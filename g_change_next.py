import streamlit as st
import pandas as pd
import re
import unicodedata
import io
import os
from pathlib import Path
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼‰
# ===============================
def check_password():
    """st.secrets['password'] ã¨ä¸€è‡´ã™ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³"""
    def password_entered():
        """ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«å…¥åŠ›ã•ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œè¨¼"""
        if "password" not in st.secrets:
            st.session_state["password_correct"] = False
            st.session_state["password_error"] = "ã‚µãƒ¼ãƒãƒ¼å´ã«ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            return

        if st.session_state["password"] == st.secrets["password"]:
            st.session_state["password_correct"] = True
            st.session_state.pop("password", None)  # ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰æ–‡å­—åˆ—ã¯æ¶ˆã—ã¦ãŠã
            st.session_state.pop("password_error", None)
        else:
            st.session_state["password_correct"] = False
            st.session_state["password_error"] = "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚ã‚‚ã†ä¸€åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

    # åˆå›ï¼šãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›æ¬„ã‚’è¡¨ç¤º
    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False

    if not st.session_state["password_correct"]:
        st.title("ğŸ” G-Change Next ãƒ­ã‚°ã‚¤ãƒ³")
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            type="password",
            on_change=password_entered,
            key="password",
        )
        if "password_error" in st.session_state and st.session_state["password_error"]:
            st.error(st.session_state["password_error"])
        # ã“ã“ã§å‡¦ç†ã‚’ã‚¹ãƒˆãƒƒãƒ—ï¼ˆã‚¢ãƒ—ãƒªæœ¬ä½“ã¯ã¾ã è¡¨ç¤ºã—ãªã„ï¼‰
        return False

    # èªè¨¼æ¸ˆã¿
    return True

# ===============================
# Streamlitè¨­å®š
# ===============================
st.set_page_config(page_title="G-Change Next", layout="wide")

# â–¼ã“ã“ã§ãƒ­ã‚°ã‚¤ãƒ³ãƒã‚§ãƒƒã‚¯ã€‚å¤±æ•—ã—ãŸã‚‰ä»¥é™ã®å‡¦ç†ã¯å®Ÿè¡Œã•ã‚Œãªã„
if not check_password():
    st.stop()

st.title("ğŸš— G-Change Nextï½œä¼æ¥­æƒ…å ±æ•´å½¢ï¼†NGé™¤å¤–ãƒ„ãƒ¼ãƒ«ï¼ˆVer6.3 è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‹ç¢ºå®šãƒœã‚¿ãƒ³çœç•¥ç‰ˆï¼‰")

# ===============================
# ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
# ===============================
def nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s)

def normalize_text(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).replace("\u3000", " ").replace("\xa0", " ")
    s = re.sub(r'[âˆ’â€“â€”â€•ãƒ¼]', '-', s)
    return nfkc(s).strip()

def clean_address(address: str) -> str:
    address = normalize_text(address)
    return address.strip()

def extract_industry(line: str) -> str:
    return normalize_text(line)

# ===============================
# ä¼æ¥­åæ­£è¦åŒ–ï¼ˆNGç…§åˆç”¨ï¼‰
# ===============================
COMPANY_SUFFIXES = ["æ ªå¼ä¼šç¤¾", "(æ ª)", "ï¼ˆæ ªï¼‰", "æœ‰é™ä¼šç¤¾", "(æœ‰)", "ï¼ˆæœ‰ï¼‰", "åˆåŒä¼šç¤¾"]
def canonical_company_name(name: str) -> str:
    s = normalize_text(name)
    for suf in sorted(COMPANY_SUFFIXES, key=len, reverse=True):
        s = s.replace(suf, "")
    s = re.sub(r"[\s\-ãƒ»/,.Â·ï½¥\(\)ï¼ˆï¼‰ã€ã€‘ï¼†&ï¼‹+_|]", "", s)
    return s

# ===============================
# é›»è©±ç•ªå·å‡¦ç†ï¼ˆåŸæ–‡ä¿æŒï¼‰
# ===============================
HYPHENS = "-â€’â€“â€”â€•âˆ’ï¼ãƒ¼â€ï¹£\u2011"
HYPHENS_CLASS = re.escape(HYPHENS)

# é›»è©±ç•ªå·å€™è£œæŠ½å‡ºï¼ˆèª¤æ¤œå‡ºé˜²æ­¢ï¼‰: æ•°å­—ï¼‹ãƒã‚¤ãƒ•ãƒ³/ç©ºç™½ãŒç¶šã8æ–‡å­—ä»¥ä¸Šã®å¡Š
CANDIDATE_RE = re.compile(rf"[+]?\d(?:[\d{HYPHENS_CLASS}\s]{{6,}})\d")

def pick_phone_token_raw(line: str) -> str:
    """1è¡Œã‹ã‚‰é›»è©±ç•ªå·ã‚‰ã—ã„æ–‡å­—åˆ—ã‚’æŠ½å‡ºã€‚digits é•·ãŒ 9ã€œ11 ä»¥å¤–ã¯ä¸æ¡ç”¨ã€‚åŸæ–‡è¡¨è¨˜ï¼ˆãƒã‚¤ãƒ•ãƒ³ä½ç½®ï¼‰ã‚’ãã®ã¾ã¾è¿”ã™ã€‚"""
    if not line:
        return ""
    s = unicodedata.normalize("NFKC", str(line))
    raw_cands = CANDIDATE_RE.findall(s)
    cands = []
    for token in raw_cands:
        tok = token.strip()
        if ":" in tok:           # æ™‚åˆ»æ··å…¥ãªã©ã¯é™¤å¤–
            continue
        digits = re.sub(r"\D", "", tok)
        if not (9 <= len(digits) <= 11):
            continue             # 11-10 ã®ã‚ˆã†ãªçŸ­ã„å¡Šã¯é™¤å¤–
        if not (digits.startswith("0") or digits.startswith("81")):
            continue             # å›½å†…å…ˆé ­0 or å›½ç•ªå·81ã®ã¿è¨±å¯
        score = (len(digits), tok.count("-"))  # é•·ã„digitsï¼†ãƒã‚¤ãƒ•ãƒ³å¤šã„ï¼é›»è©±ã£ã½ã„
        cands.append((score, tok))
    if not cands:
        return ""
    cands.sort(key=lambda x: x[0], reverse=True)
    return cands[0][1]

def phone_digits_only(s: str) -> str:
    """å†…éƒ¨ç…§åˆç”¨ã«æ•°å­—ã ã‘æŠ½å‡ºï¼ˆåŸæ–‡è¡¨è¨˜ã¯ä¿æŒï¼‰"""
    return re.sub(r"\D", "", str(s or ""))

# ===============================
# æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3æ–¹å¼ï¼‰
# ===============================
# 1) Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹ï¼‰
def extract_google_vertical(lines):
    results = []
    rows = [str(l) for l in lines if str(l).strip() != ""]
    for i, line in enumerate(rows):
        ph_raw = pick_phone_token_raw(line)
        if ph_raw:
            phone = ph_raw  # åŸæ–‡ä¿æŒ
            address = rows[i - 1] if i - 1 >= 0 else ""
            industry = extract_industry(rows[i - 2]) if i - 2 >= 0 else ""
            company = rows[i - 3] if i - 3 >= 0 else ""
            results.append([company, industry, clean_address(address), phone])
    return pd.DataFrame(results, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# 2) ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯ï¼ˆç¸¦ç©ã¿ï¼‰
def extract_shigoto_arua(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.copy()
    if df.columns.size > 2:
        df = df.iloc[:, :2]
    df.columns = ["col0", "col1"]
    df = df.fillna("")
    current = {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""}
    out = []

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], current["æ¥­ç¨®"], current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""})

    for _, row in df.iterrows():
        k, v = str(row["col0"]), str(row["col1"])
        if k in ["ä½æ‰€", "æ‰€åœ¨åœ°", "æœ¬ç¤¾æ‰€åœ¨åœ°"]:
            current["ä½æ‰€"] = clean_address(v)
        elif k in ["é›»è©±", "é›»è©±ç•ªå·", "TEL", "Tel", "tel"]:
            current["é›»è©±ç•ªå·"] = v  # åŸæ–‡ä¿æŒ
        elif k in ["æ¥­ç¨®", "äº‹æ¥­å†…å®¹", "ç”£æ¥­åˆ†é¡", "è£½é€ æ¥­ç¨®"]:
            current["æ¥­ç¨®"] = extract_industry(v)
        elif k and not v:
            if current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = k
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# 3) æ—¥æœ¬å€‰åº«å”ä¼šï¼ˆ4åˆ—ï¼‰
def extract_warehouse_association(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.fillna("")
    if df.shape[1] < 2:
        return pd.DataFrame(columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])
    while df.shape[1] < 4:
        df[f"__pad{df.shape[1]}"] = ""
    df = df.iloc[:, :4]
    df.columns = ["c0", "c1", "c2", "c3"]

    tel_re = re.compile(r"(?:TEL|Tel|tel)\s*([0-9ï¼-ï¼™\-ãƒ¼ï¼\s]+)")
    out, current = [], {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()}

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], "ãƒ»".join(current["æ¥­ç¨®_set"]), current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()})

    for _, r in df.iterrows():
        if r["c0"]:
            if current["ä¼æ¥­å"] and r["c0"] != current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = r["c0"]
        if r["c1"]:
            current["ä½æ‰€"] = clean_address(r["c1"])
        if r["c2"]:
            m = tel_re.search(r["c2"])
            if m:
                current["é›»è©±ç•ªå·"] = m.group(1).strip()  # åŸæ–‡ä¿æŒ
        if r["c3"]:
            current["æ¥­ç¨®_set"].add(extract_industry(r["c3"]))
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# ===============================
# æ¥­ç¨®ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼/ãƒã‚¤ãƒ©ã‚¤ãƒˆ
# ===============================
remove_exact = [
    "ã‚ªãƒ•ã‚£ã‚¹æ©Ÿå™¨ãƒ¬ãƒ³ã‚¿ãƒ«æ¥­", "è¶³å ´ãƒ¬ãƒ³ã‚¿ãƒ«ä¼šç¤¾", "é›»æ°—å·¥", "å»ƒæ£„ç‰©ãƒªã‚µã‚¤ã‚¯ãƒ«æ¥­",
    "ãƒ—ãƒ­ãƒ‘ãƒ³è²©å£²æ¥­è€…", "çœ‹æ¿å°‚é–€åº—", "çµ¦æ°´è¨­å‚™å·¥å ´", "è­¦å‚™æ¥­", "å»ºè¨­ä¼šç¤¾",
    "å·¥å‹™åº—", "å†™çœŸåº—", "äººææ´¾é£æ¥­", "æ•´å‚™åº—", "å€‰åº«", "è‚‰åº—", "ç±³è²©å£²åº—",
    "ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ¼ã‚±ãƒƒãƒˆ", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚µãƒ¼ãƒ“ã‚¹", "å»ºæåº—",
    "è‡ªå‹•è»Šæ•´å‚™å·¥å ´", "è‡ªå‹•è»Šè²©å£²åº—", "è»Šä½“æ•´å‚™åº—", "å”ä¼š/çµ„ç¹”", "å»ºè¨­è«‹è² æ¥­è€…", "é›»å™¨åº—", "å®¶é›»é‡è²©åº—", "å»ºç¯‰ä¼šç¤¾", "ãƒã‚¦ã‚¹ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¥­", "ç„¼è‚‰åº—",
    "å»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€", "å·¦å®˜", "ä½œæ¥­æœåº—", "ç©ºèª¿è¨­å‚™å·¥äº‹æ¥­è€…", "é‡‘å±ã‚¹ã‚¯ãƒ©ãƒƒãƒ—æ¥­è€…", "å®³ç£é§†é™¤ã‚µãƒ¼ãƒ“ã‚¹", "ãƒ¢ãƒ¼ã‚¿ãƒ¼ä¿®ç†åº—", "ã‚¢ãƒ¼ãƒã‚§ãƒªãƒ¼ã‚·ãƒ§ãƒƒãƒ—", "ã‚¢ã‚¹ãƒ™ã‚¹ãƒˆæ¤œæŸ»æ¥­", "äº‹å‹™ç”¨å“åº—",
    "æ¸¬é‡å£«", "é…ç®¡æ¥­è€…", "åŠ´åƒçµ„åˆ", "ã‚¬ã‚¹ä¼šç¤¾", "ã‚¬ã‚½ãƒªãƒ³ã‚¹ã‚¿ãƒ³ãƒ‰", "ã‚¬ãƒ©ã‚¹/ãƒŸãƒ©ãƒ¼åº—", "ãƒ¯ã‚¤ãƒŠãƒªãƒ¼", "å±‹æ ¹ãµãæ¥­è€…", "é«˜ç­‰å­¦æ ¡", "é‡‘ç‰©åº—", "å²è·¡", "å•†å·¥ä¼šè­°æ‰€", "æ¸…æƒæ¥­", "æ¸…æƒæ¥­è€…", "é…ç®¡å·¥"
]
remove_partial = ["è²©å£²åº—", "è²©å£²æ¥­è€…"]

highlight_partial = [
    "é‹è¼¸", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚µãƒ¼ãƒ“ã‚¹", "å€‰åº«", "è¼¸é€ã‚µãƒ¼ãƒ“ã‚¹",
    "é‹é€ä¼šç¤¾ä¼æ¥­ã®ã‚ªãƒ•ã‚£ã‚¹", "é‹é€ä¼šç¤¾"
]

# ===============================
# æ¥­ç¨®ãƒã‚¤ã‚ºé™¤å»ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼/è©•ä¾¡ãªã©ï¼‰
# ===============================
def clean_industry_noise(s: str) -> str:
    """
    æ¥­ç¨®ã‚«ãƒ©ãƒ ã«ç´›ã‚Œè¾¼ã‚€
    - ãƒ¬ãƒ“ãƒ¥ãƒ¼æƒ…å ±ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãªã—ãƒ»â€¦ï¼‰
    - Google ã®ã‚¯ãƒã‚³ãƒŸ
    - â—‹ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼å£ã‚³ãƒŸ
    ãªã©ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã™ã‚‹
    ï¼‹ æœ€å¾Œã«ã€ŒÂ·ã€ã€Œãƒ¬ãƒ“ãƒ¥-ãªã—ã€ã€Œç©ºç™½ã ã‘ã€ã¯å¿…ãšæ¶ˆã™
    """
    if not s:
        return ""
    t = str(s)
    # ç©ºç™½ã‚’ã‚†ã‚‹ãæ­£è¦åŒ–
    t = re.sub(r"\s+", " ", t).strip()

    # å…ˆé ­ã®è©•ä¾¡ã‚¹ã‚³ã‚¢ + ä»¶æ•° ä¾‹: '4.7(123)ãƒ»', '4.7ï¼ˆ123ï¼‰ãƒ»'
    t = re.sub(r"^\s*\d+(?:\.\d+)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]\s*(?:ä»¶)?\s*[ãƒ»ï½¥]?\s*", "", t)

    # ---- ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»ãªã—ãƒ»â—‹â—‹ã€ç³»ã‚’ãƒˆãƒ¼ã‚¯ãƒ³å˜ä½ã§å‡¦ç† ----
    def norm_token(x: str) -> str:
        return re.sub(r"\s+", "", x)

    noise_basic = {"ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç„¡ã—", "ã‚¯ãƒã‚³ãƒŸ", "å£ã‚³ãƒŸ"}
    noise_nashi = {"ãªã—"}

    if t.startswith("ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        parts = [p.strip() for p in re.split(r"[ãƒ»ï½¥]", t) if p.strip()]
        if not parts:
            return ""

        # å…¨éƒ¨ãƒã‚¤ã‚ºãªã‚‰ç©ºã«ã™ã‚‹
        if all(norm_token(p) in noise_basic | noise_nashi for p in parts):
            return ""

        cleaned_parts = []
        for p in parts:
            pn = norm_token(p)
            if pn in noise_basic or pn in noise_nashi:
                continue
            cleaned_parts.append(p)

        t = "ãƒ»".join(cleaned_parts)
    else:
        # ã€ŒGoogle ã®ã‚¯ãƒã‚³ãƒŸã€ã€Œå£ã‚³ãƒŸã€ã€Œã‚¯ãƒã‚³ãƒŸã€ãªã©ãŒé€”ä¸­ã«ã‚ã‚‹å ´åˆ
        t = re.sub(r"(?:^|[ãƒ»ï½¥])\s*(Google\s*ã®?\s*ã‚¯ãƒã‚³ãƒŸ|å£ã‚³ãƒŸ|ã‚¯ãƒã‚³ãƒŸ)\s*(?=[ãƒ»ï½¥]|$)", "", t)
        # ã€Œâ—¯ä»¶ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œâ—¯ä»¶ã®å£ã‚³ãƒŸã€ãªã©
        t = re.sub(r"[ãƒ»ï½¥]?\s*\d+\s*ä»¶ã®?(ãƒ¬ãƒ“ãƒ¥ãƒ¼|å£ã‚³ãƒŸ|ã‚¯ãƒã‚³ãƒŸ)\s*(?=[ãƒ»ï½¥]|$)", "", t)

    # åˆ†å‰²ã—ã¦ç©ºè¦ç´ ã‚’å‰Šé™¤
    parts = [p.strip() for p in re.split(r"[ãƒ»ï½¥]", t) if p.strip()]
    t = "ãƒ»".join(parts) if parts else ""

    # ä½™è¨ˆãªåŒºåˆ‡ã‚Šã‚„ç©ºç™½ã‚’æ•´å½¢
    t = re.sub(r"[ãƒ»ï½¥]{2,}", "ãƒ»", t).strip(" ãƒ»ï½¥")

    # â–¼â–¼â–¼ ã“ã“ãŒã€Œå¿…ãšæ¶ˆã™ã€éƒ¨åˆ† â–¼â–¼â–¼
    # ä¸­é»’ã€ŒÂ·ã€ã‚„ã€Œãƒ¬ãƒ“ãƒ¥-ãªã—ã€ã‚’å¼·åˆ¶å‰Šé™¤
    if t:
        for trash in ["Â·", "ãƒ¬ãƒ“ãƒ¥-ãªã—"]:
            t = t.replace(trash, "")
        # ã¤ã„ã§ã«å…¨è§’/åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã ã‘ã«ãªã£ãŸå ´åˆã‚‚ç©ºã«ã™ã‚‹
        t = re.sub(r"\s+", " ", t).strip()

    return t if t else ""

# ===============================
# å…±é€šæ•´å½¢ï¼ˆé›»è©±ã¯è§¦ã‚‰ãªã„ï¼‰
# ===============================
def clean_dataframe_except_phone(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€"]:
        df[c] = df[c].map(normalize_text)
    df["æ¥­ç¨®"] = df["æ¥­ç¨®"].map(clean_industry_noise)
    return df.fillna("")

# ===============================
# UIï¼ˆNGãƒªã‚¹ãƒˆé¸æŠãƒ»æŠ½å‡ºæ–¹å¼ãƒ»æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå…¥åŠ›ï¼‰
# ===============================
st.markdown("### ğŸ›¡ï¸ ä½¿ç”¨ã™ã‚‹NGãƒªã‚¹ãƒˆã‚’é¸æŠ")
nglist_files = [f for f in os.listdir() if f.endswith(".xlsx") and "NGãƒªã‚¹ãƒˆ" in f]
nglist_options = ["ãªã—"] + [os.path.splitext(f)[0] for f in nglist_files]
selected_nglist = st.selectbox(
    "NGãƒªã‚¹ãƒˆ",
    nglist_options,
    index=0,
    help="åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã€NGãƒªã‚¹ãƒˆã€œ.xlsxã€ã‚’æ¤œå‡ºã—ã¾ã™ã€‚1åˆ—ç›®=ä¼æ¥­åã€2åˆ—ç›®=é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰ã€‚"
)

st.markdown("### ğŸ§­ æŠ½å‡ºæ–¹æ³•ã‚’é¸æŠ")
profile = st.selectbox(
    "æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«",
    ["Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰", "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰", "æ—¥æœ¬å€‰åº«å”ä¼šãƒªã‚¹ãƒˆï¼ˆ4åˆ—å‹ï¼‰"]
)

st.markdown("### ğŸ­ æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ")
industry_option = st.radio("ã©ã®æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«è©²å½“ã—ã¾ã™ã‹ï¼Ÿ", ("è£½é€ æ¥­", "ç‰©æµæ¥­", "ãã®ä»–"))

st.markdown("### ğŸ§© ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—æ–¹æ³•ï¼ˆOSäº’æ›å¼·åŒ–ï¼‰")
template_source = st.radio(
    "template.xlsx ã®å–å¾—å…ƒ",
    ("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã® template.xlsx ã‚’ä½¿ã†ï¼ˆå¾“æ¥ï¼‰", "ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†"),
    index=0
)
template_upload = None
if template_source == "ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†":
    template_upload = st.file_uploader("template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], key="template_up")

# â˜… è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼šaccept_multiple_files=True
uploaded_files = st.file_uploader(
    "ğŸ“¤ æ•´å½¢å¯¾è±¡ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
    type=["xlsx"],
    accept_multiple_files=True
)

# ===============================
# NGãƒªã‚¹ãƒˆã‚’ä¸€åº¦ã ã‘èª­ã¿è¾¼ã‚“ã§å…±æœ‰ï¼ˆæŒ™å‹•ã¯å¾“æ¥ã¨åŒã˜ï¼‰
# ===============================
ng_names = []
ng_phones = set()
if uploaded_files and selected_nglist != "ãªã—":
    ng_path = f"{selected_nglist}.xlsx"
    if not os.path.exists(ng_path):
        st.error(f"âŒ é¸æŠã•ã‚ŒãŸNGãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼š{ng_path}")
        st.stop()
    ng_df = pd.read_excel(ng_path, engine="openpyxl").fillna("")
    if ng_df.shape[1] < 1:
        st.error("âŒ NGãƒªã‚¹ãƒˆã¯å°‘ãªãã¨ã‚‚1åˆ—ï¼ˆä¼æ¥­åï¼‰ãŒå¿…è¦ã§ã™ã€‚2åˆ—ç›®ã«é›»è©±ç•ªå·ãŒã‚ã‚Œã°ç…§åˆã«åˆ©ç”¨ã—ã¾ã™ã€‚")
        st.stop()
    ng_df["__ng_company_canon"] = ng_df.iloc[:, 0].map(canonical_company_name)
    if ng_df.shape[1] >= 2:
        ng_df["__ng_digits"] = ng_df.iloc[:, 1].astype(str).map(phone_digits_only)
    else:
        ng_df["__ng_digits"] = ""
    ng_names = [n for n in ng_df["__ng_company_canon"].tolist() if n]
    ng_phones = set([d for d in ng_df["__ng_digits"].tolist() if d])

# ===============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆâ˜…ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ç‹¬ç«‹ã—ã¦å‡¦ç†ï¼‰
# ===============================
if uploaded_files:
    for file_index, uploaded_file in enumerate(uploaded_files):
        st.markdown("---")
        st.markdown(f"## ğŸ“ {uploaded_file.name}")

        filename_no_ext = os.path.splitext(uploaded_file.name)[0]
        xl = pd.ExcelFile(uploaded_file, engine="openpyxl")

        # --- æŠ½å‡º ---
        if "å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼" in xl.sheet_names:
            # templateäº’æ›: å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼ã‹ã‚‰èª­ã¿å–ã‚Šï¼ˆé›»è©±ã¯åŸæ–‡ã®ã¾ã¾ï¼‰
            df_raw = pd.read_excel(
                xl,
                sheet_name="å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼",
                header=None,
                engine="openpyxl"
            ).fillna("")
            df = pd.DataFrame({
                "ä¼æ¥­å": df_raw.iloc[1:, 1].astype(str),
                "æ¥­ç¨®": df_raw.iloc[1:, 2].astype(str),
                "ä½æ‰€": df_raw.iloc[1:, 3].astype(str),
                "é›»è©±ç•ªå·": df_raw.iloc[1:, 4].astype(str),
            })
        else:
            # å¾“æ¥ã®3ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
            if profile == "Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰":
                df0 = pd.read_excel(uploaded_file, header=None, engine="openpyxl").fillna("")
                lines = df0.iloc[:, 0].tolist()
                df = extract_google_vertical(lines)
            elif profile == "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰":
                df0 = pd.read_excel(xl, header=None, engine="openpyxl").fillna("")
                df = extract_shigoto_arua(df0)
            else:
                df0 = pd.read_excel(xl, header=None, engine="openpyxl").fillna("")
                df = extract_warehouse_association(df0)

        # --- éé›»è©±åˆ—ã®ã¿æ­£è¦åŒ– ---
        df = clean_dataframe_except_phone(df)

        # --- æ¯”è¼ƒã‚­ãƒ¼ ---
        df["__company_canon"] = df["ä¼æ¥­å"].map(canonical_company_name)
        df["__digits"] = df["é›»è©±ç•ªå·"].map(phone_digits_only)

        # --- æ¥­ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè£½é€ æ¥­ã®ã¿é™¤å¤–ãƒ«ãƒ¼ãƒ«é©ç”¨ï¼‰ ---
        removed_by_industry = 0
        if industry_option == "è£½é€ æ¥­":
            before = len(df)
            # remove_exact ã¨ remove_partial ã‚’ã¾ã¨ã‚ã¦ã€Œéƒ¨åˆ†ä¸€è‡´ NG ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã¨ã—ã¦æ‰±ã†
            all_ng_words = remove_exact + remove_partial
            if all_ng_words:
                pat = "|".join(map(re.escape, all_ng_words))
                df = df[~df["æ¥­ç¨®"].str.contains(pat, na=False)]
            removed_by_industry = before - len(df)
            st.warning(f"ğŸ­ è£½é€ æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼š{removed_by_industry}ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ")

        # --- NGç…§åˆï¼ˆä»»æ„ï¼‰ ---
        removal_logs = []
        company_removed = 0
        phone_removed = 0
        dup_removed = 0

        if ng_names or ng_phones:
            # ä¼æ¥­åï¼ˆéƒ¨åˆ†ä¸€è‡´ãƒ»ç›¸äº’åŒ…å«ï¼‰
            before = len(df)
            hit_idx = []
            for idx, row in df.iterrows():
                c = row["__company_canon"]
                if not c:
                    continue
                if any((n in c or c in n) for n in ng_names):
                    removal_logs.append({
                        "reason": "ng-company",
                        "company": row["ä¼æ¥­å"],
                        "phone_raw": row["é›»è©±ç•ªå·"],
                        "match": c
                    })
                    hit_idx.append(idx)
            if hit_idx:
                df = df.drop(index=hit_idx)
            company_removed = before - len(df)

            # é›»è©±ç•ªå·digitsä¸€è‡´
            before = len(df)
            mask = df["__digits"].isin(ng_phones)
            if mask.any():
                for idx, row in df[mask].iterrows():
                    removal_logs.append({
                        "reason": "ng-phone",
                        "company": row["ä¼æ¥­å"],
                        "phone_raw": row["é›»è©±ç•ªå·"],
                        "match": row["__digits"]
                    })
                df = df[~mask]
            phone_removed = before - len(df)

        # --- é‡è¤‡ï¼ˆé›»è©±digitsï¼‰é™¤å»ï¼ˆâ€»ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«å†…ã ã‘ï¼‰ ---
        before = len(df)
        dup_mask = df["__digits"].ne("").astype(bool) & df["__digits"].duplicated(keep="first")
        if dup_mask.any():
            for idx, row in df[dup_mask].iterrows():
                removal_logs.append({
                    "reason": "dup-phone",
                    "company": row["ä¼æ¥­å"],
                    "phone_raw": row["é›»è©±ç•ªå·"],
                    "match": row["__digits"]
                })
            df = df[~dup_mask]
        dup_removed = before - len(df)

        # --- ç©ºè¡Œã®é™¤å» ---
        df = df[~((df["ä¼æ¥­å"] == "") & (df["æ¥­ç¨®"] == "") & (df["ä½æ‰€"] == "") & (df["é›»è©±ç•ªå·"] == ""))].reset_index(drop=True)

        # --- ç”»é¢è¡¨ç¤ºï¼ˆç·¨é›†å¯ãƒ»ç¢ºå®šãƒœã‚¿ãƒ³ãªã—ï¼‰ ---
        st.success(f"âœ… æ•´å½¢å®Œäº†ï¼š{len(df)}ä»¶ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        edited = st.data_editor(
            df[["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"]],
            use_container_width=True,
            num_rows="fixed",
            column_config={
                "ä¼æ¥­å": st.column_config.TextColumn(required=True),
                "æ¥­ç¨®": st.column_config.TextColumn(),
                "ä½æ‰€": st.column_config.TextColumn(),
                "é›»è©±ç•ªå·": st.column_config.TextColumn(
                    help="åŸæ–‡ã®é…åˆ—ã‚’ä¿æŒã€‚å¿…è¦ãªã‚‰ã“ã“ã§æ‰‹å‹•ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚ç·¨é›†å†…å®¹ã¯ãã®ã¾ã¾å‡ºåŠ›ã«åæ˜ ã•ã‚Œã¾ã™ã€‚"
                ),
            },
            key=f"editable_preview_{file_index}",
        )

        # ç¢ºå®šãƒœã‚¿ãƒ³ã¯å»ƒæ­¢ã€‚edited ã‚’ãã®ã¾ã¾å‡ºåŠ›ç”¨ã«ä½¿ã†
        df_export = edited.copy()

        # --- ã‚µãƒãƒªãƒ¼ï¼†å‰Šé™¤ãƒ­ã‚°DL ---
        with st.expander(f"ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼ï¼ˆè©³ç´°ï¼‰ - {uploaded_file.name}", expanded=False):
            st.markdown(
                f"- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é™¤å¤–ï¼ˆè£½é€ æ¥­ éƒ¨åˆ†ä¸€è‡´ï¼‰: **{removed_by_industry}** ä»¶\n"
                f"- NGï¼ˆä¼æ¥­å éƒ¨åˆ†ä¸€è‡´ï¼‰å‰Šé™¤: **{company_removed}** ä»¶\n"
                f"- NGï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{phone_removed}** ä»¶\n"
                f"- é‡è¤‡ï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{dup_removed}** ä»¶\n"
            )
            if removal_logs:
                log_df = pd.DataFrame(removal_logs)
                st.dataframe(log_df.head(300), use_container_width=True)
                csv_bytes = log_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ§¾ å‰Šé™¤ãƒ­ã‚°ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_bytes,
                    file_name=f"removal_logs_{filename_no_ext}.csv",
                    mime="text/csv",
                    key=f"removal_log_btn_{file_index}",
                )

        # ===============================
        # template.xlsx ã¸æ›¸ãè¾¼ã¿ï¼ˆOSäº’æ›å¼·åŒ–ï¼‰
        # ===============================
        # 1) ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ template.xlsx ã‚’å„ªå…ˆ
        wb = None
        if template_upload is not None:
            try:
                buf = io.BytesIO(template_upload.read())
                wb = load_workbook(buf)
            except Exception as e:
                st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸ template.xlsx ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()
        else:
            # 2) ã‚¹ã‚¯ãƒªãƒ—ãƒˆç›¸å¯¾ãƒ‘ã‚¹ã§è§£æ±ºï¼ˆä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå·®ã‚’å¸åï¼‰
            app_dir = Path(__file__).resolve().parent
            template_path = app_dir / "template.xlsx"
            if not template_path.exists():
                st.error(
                    f"âŒ template.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆæœŸå¾…ãƒ‘ã‚¹: {template_path}ï¼‰ã€‚"
                    "ã€ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†ã€ã‚’é¸ã¶ã‹ã€"
                    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚"
                )
                st.stop()
            try:
                wb = load_workbook(template_path)
            except Exception as e:
                st.error(f"âŒ template.xlsx ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

        if "å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼" not in wb.sheetnames:
            st.error("âŒ template.xlsx ã«ã€å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼ã€ã¨ã„ã†ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            st.stop()

        sheet = wb["å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼"]

        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ï¼ˆ2è¡Œç›®ä»¥é™ã®Bã€œEï¼‰ã¨å¡—ã‚Šã‚’ã‚¯ãƒªã‚¢
        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row):
            for cell in row[1:5]:  # B(1)ã€œE(4)
                cell.value = None
                cell.fill = PatternFill(fill_type=None)

        # ç‰©æµãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆæ¥­ç¨®ã«ç‰¹å®šèªãŒå«ã¾ã‚Œã‚‹å ´åˆã€Cåˆ—ã‚’èµ¤ãï¼‰
        red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

        def is_logi(val: str) -> bool:
            v = (val or "").strip()
            return any(word in v for word in highlight_partial)

        # ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ï¼ˆB=ä¼æ¥­å, C=æ¥­ç¨®, D=ä½æ‰€, E=é›»è©±ï¼‰
        for idx_row, row in df_export.iterrows():
            r = idx_row + 2
            sheet.cell(row=r, column=2, value=row["ä¼æ¥­å"])
            sheet.cell(row=r, column=3, value=row["æ¥­ç¨®"])
            sheet.cell(row=r, column=4, value=row["ä½æ‰€"])
            sheet.cell(row=r, column=5, value=row["é›»è©±ç•ªå·"])
            if industry_option == "ç‰©æµæ¥­" and is_logi(row["æ¥­ç¨®"]):
                sheet.cell(row=r, column=3).fill = red_fill

        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«åˆ¥ãƒœã‚¿ãƒ³ï¼‰
        output = io.BytesIO()
        wb.save(output)
        output.seek(0)
        st.download_button(
            label=f"ğŸ“¥ æ•´å½¢æ¸ˆã¿ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ{filename_no_ext} / template.xlsx åæ˜ ï¼‰",
            data=output,
            file_name=f"{filename_no_ext}ãƒªã‚¹ãƒˆ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key=f"download_btn_{file_index}",
        )

else:
    st.info("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚NGãƒªã‚¹ãƒˆxlsxã¯åŒãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ãã‹ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
