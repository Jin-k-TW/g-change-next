import streamlit as st
import pandas as pd
import re
import unicodedata
import io
import os
from pathlib import Path
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# Streamlitè¨­å®š
# ===============================
st.set_page_config(page_title="G-Change Next", layout="wide")
st.title("ğŸš— G-Change Nextï½œä¼æ¥­æƒ…å ±æ•´å½¢ï¼†NGé™¤å¤–ãƒ„ãƒ¼ãƒ«ï¼ˆVer6.2 åŸæ–‡é›»è©±ä¿æŒï¼‹NGç…§åˆï¼‹templateæ›¸ãè¾¼ã¿ï¼‹å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼å„ªå…ˆï¼‹OSäº’æ›å¼·åŒ–ï¼‰")

# ===============================
# ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
# ===============================
def nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s)

def normalize_text(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).replace("\u3000", " ").replace("\xa0", " ")
    s = re.sub(r'[âˆ’â€“â€”â€•ãƒ¼]', '-', s)
    return nfkc(s).strip()

def clean_address(address: str) -> str:
    address = normalize_text(address)
    return address.strip()

def extract_industry(line: str) -> str:
    return normalize_text(line)

# ===============================
# ä¼æ¥­åæ­£è¦åŒ–ï¼ˆNGç…§åˆç”¨ï¼‰
# ===============================
COMPANY_SUFFIXES = ["æ ªå¼ä¼šç¤¾", "(æ ª)", "ï¼ˆæ ªï¼‰", "æœ‰é™ä¼šç¤¾", "(æœ‰)", "ï¼ˆæœ‰ï¼‰", "åˆåŒä¼šç¤¾"]
def canonical_company_name(name: str) -> str:
    s = normalize_text(name)
    for suf in sorted(COMPANY_SUFFIXES, key=len, reverse=True):
        s = s.replace(suf, "")
    s = re.sub(r"[\s\-ãƒ»/,.Â·ï½¥\(\)ï¼ˆï¼‰ã€ã€‘ï¼†&ï¼‹+_|]", "", s)
    return s

# ===============================
# é›»è©±ç•ªå·å‡¦ç†ï¼ˆåŸæ–‡ä¿æŒï¼‰
# ===============================
HYPHENS = "-â€’â€“â€”â€•âˆ’ï¼ãƒ¼â€ï¹£\u2011"
HYPHENS_CLASS = re.escape(HYPHENS)

# é›»è©±ç•ªå·å€™è£œæŠ½å‡ºï¼ˆèª¤æ¤œå‡ºé˜²æ­¢ï¼‰: æ•°å­—ï¼‹ãƒã‚¤ãƒ•ãƒ³/ç©ºç™½ãŒç¶šã8æ–‡å­—ä»¥ä¸Šã®å¡Š
CANDIDATE_RE = re.compile(rf"[+]?\d(?:[\d{HYPHENS_CLASS}\s]{{6,}})\d")

def pick_phone_token_raw(line: str) -> str:
    """1è¡Œã‹ã‚‰é›»è©±ç•ªå·ã‚‰ã—ã„æ–‡å­—åˆ—ã‚’æŠ½å‡ºã€‚digits é•·ãŒ 9ã€œ11 ä»¥å¤–ã¯ä¸æ¡ç”¨ã€‚åŸæ–‡è¡¨è¨˜ï¼ˆãƒã‚¤ãƒ•ãƒ³ä½ç½®ï¼‰ã‚’ãã®ã¾ã¾è¿”ã™ã€‚"""
    if not line:
        return ""
    s = unicodedata.normalize("NFKC", str(line))
    raw_cands = CANDIDATE_RE.findall(s)
    cands = []
    for token in raw_cands:
        tok = token.strip()
        if ":" in tok:           # æ™‚åˆ»æ··å…¥ãªã©ã¯é™¤å¤–
            continue
        digits = re.sub(r"\D", "", tok)
        if not (9 <= len(digits) <= 11):
            continue             # 11-10 ã®ã‚ˆã†ãªçŸ­ã„å¡Šã¯é™¤å¤–
        if not (digits.startswith("0") or digits.startswith("81")):
            continue             # å›½å†…å…ˆé ­0 or å›½ç•ªå·81ã®ã¿è¨±å¯
        score = (len(digits), tok.count("-"))  # é•·ã„digitsï¼†ãƒã‚¤ãƒ•ãƒ³å¤šã„ï¼é›»è©±ã£ã½ã„
        cands.append((score, tok))
    if not cands:
        return ""
    cands.sort(key=lambda x: x[0], reverse=True)
    return cands[0][1]

def phone_digits_only(s: str) -> str:
    """å†…éƒ¨ç…§åˆç”¨ã«æ•°å­—ã ã‘æŠ½å‡ºï¼ˆåŸæ–‡è¡¨è¨˜ã¯ä¿æŒï¼‰"""
    return re.sub(r"\D", "", str(s or ""))

# ===============================
# æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3æ–¹å¼ï¼‰
# ===============================
# 1) Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹ï¼‰
def extract_google_vertical(lines):
    results = []
    rows = [str(l) for l in lines if str(l).strip() != ""]
    for i, line in enumerate(rows):
        ph_raw = pick_phone_token_raw(line)
        if ph_raw:
            phone = ph_raw  # åŸæ–‡ä¿æŒ
            address = rows[i - 1] if i - 1 >= 0 else ""
            industry = extract_industry(rows[i - 2]) if i - 2 >= 0 else ""
            company = rows[i - 3] if i - 3 >= 0 else ""
            results.append([company, industry, clean_address(address), phone])
    return pd.DataFrame(results, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# 2) ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯ï¼ˆç¸¦ç©ã¿ï¼‰
def extract_shigoto_arua(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.copy()
    if df.columns.size > 2:
        df = df.iloc[:, :2]
    df.columns = ["col0", "col1"]
    df = df.fillna("")
    current = {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""}
    out = []

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], current["æ¥­ç¨®"], current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""})

    for _, row in df.iterrows():
        k, v = str(row["col0"]), str(row["col1"])
        if k in ["ä½æ‰€", "æ‰€åœ¨åœ°", "æœ¬ç¤¾æ‰€åœ¨åœ°"]:
            current["ä½æ‰€"] = clean_address(v)
        elif k in ["é›»è©±", "é›»è©±ç•ªå·", "TEL", "Tel", "tel"]:
            current["é›»è©±ç•ªå·"] = v  # åŸæ–‡ä¿æŒ
        elif k in ["æ¥­ç¨®", "äº‹æ¥­å†…å®¹", "ç”£æ¥­åˆ†é¡", "è£½é€ æ¥­ç¨®"]:
            current["æ¥­ç¨®"] = extract_industry(v)
        elif k and not v:
            if current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = k
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# 3) æ—¥æœ¬å€‰åº«å”ä¼šï¼ˆ4åˆ—ï¼‰
def extract_warehouse_association(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.fillna("")
    if df.shape[1] < 2:
        return pd.DataFrame(columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])
    while df.shape[1] < 4:
        df[f"__pad{df.shape[1]}"] = ""
    df = df.iloc[:, :4]
    df.columns = ["c0", "c1", "c2", "c3"]

    tel_re = re.compile(r"(?:TEL|Tel|tel)\s*([0-9ï¼-ï¼™\-ãƒ¼ï¼\s]+)")
    out, current = [], {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()}

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], "ãƒ»".join(current["æ¥­ç¨®_set"]), current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()})

    for _, r in df.iterrows():
        if r["c0"]:
            if current["ä¼æ¥­å"] and r["c0"] != current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = r["c0"]
        if r["c1"]:
            current["ä½æ‰€"] = clean_address(r["c1"])
        if r["c2"]:
            m = tel_re.search(r["c2"])
            if m:
                current["é›»è©±ç•ªå·"] = m.group(1).strip()  # åŸæ–‡ä¿æŒ
        if r["c3"]:
            current["æ¥­ç¨®_set"].add(extract_industry(r["c3"]))
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# ===============================
# æ¥­ç¨®ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼/ãƒã‚¤ãƒ©ã‚¤ãƒˆ
# ===============================
remove_exact = [
    "ã‚ªãƒ•ã‚£ã‚¹æ©Ÿå™¨ãƒ¬ãƒ³ã‚¿ãƒ«æ¥­", "è¶³å ´ãƒ¬ãƒ³ã‚¿ãƒ«ä¼šç¤¾", "é›»æ°—å·¥", "å»ƒæ£„ç‰©ãƒªã‚µã‚¤ã‚¯ãƒ«æ¥­",
    "ãƒ—ãƒ­ãƒ‘ãƒ³è²©å£²æ¥­è€…", "çœ‹æ¿å°‚é–€åº—", "çµ¦æ°´è¨­å‚™å·¥å ´", "è­¦å‚™æ¥­", "å»ºè¨­ä¼šç¤¾",
    "å·¥å‹™åº—", "å†™çœŸåº—", "äººææ´¾é£æ¥­", "æ•´å‚™åº—", "å€‰åº«", "è‚‰åº—", "ç±³è²©å£²åº—",
    "ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ¼ã‚±ãƒƒãƒˆ", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚µãƒ¼ãƒ“ã‚¹", "å»ºæåº—",
    "è‡ªå‹•è»Šæ•´å‚™å·¥å ´", "è‡ªå‹•è»Šè²©å£²åº—", "è»Šä½“æ•´å‚™åº—", "å”ä¼š/çµ„ç¹”", "å»ºè¨­è«‹è² æ¥­è€…", "é›»å™¨åº—", "å®¶é›»é‡è²©åº—", "å»ºç¯‰ä¼šç¤¾", "ãƒã‚¦ã‚¹ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¥­", "ç„¼è‚‰åº—",
    "å»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€","å·¦å®˜","ä½œæ¥­æœåº—","ç©ºèª¿è¨­å‚™å·¥äº‹æ¥­è€…","é‡‘å±ã‚¹ã‚¯ãƒ©ãƒƒãƒ—æ¥­è€…","å®³ç£é§†é™¤ã‚µãƒ¼ãƒ“ã‚¹","ãƒ¢ãƒ¼ã‚¿ãƒ¼ä¿®ç†åº—","ã‚¢ãƒ¼ãƒã‚§ãƒªãƒ¼ã‚·ãƒ§ãƒƒãƒ—","ã‚¢ã‚¹ãƒ™ã‚¹ãƒˆæ¤œæŸ»æ¥­","äº‹å‹™ç”¨å“åº—",
    "æ¸¬é‡å£«","é…ç®¡æ¥­è€…","åŠ´åƒçµ„åˆ","ã‚¬ã‚¹ä¼šç¤¾","ã‚¬ã‚½ãƒªãƒ³ã‚¹ã‚¿ãƒ³ãƒ‰","ã‚¬ãƒ©ã‚¹/ãƒŸãƒ©ãƒ¼åº—","ãƒ¯ã‚¤ãƒŠãƒªãƒ¼","å±‹æ ¹ãµãæ¥­è€…","é«˜ç­‰å­¦æ ¡","é‡‘ç‰©åº—","å²è·¡","å•†å·¥ä¼šè­°æ‰€","æ¸…æƒæ¥­","æ¸…æƒæ¥­è€…","é…ç®¡å·¥"
]
remove_partial = ["è²©å£²åº—", "è²©å£²æ¥­è€…"]

highlight_partial = [
    "é‹è¼¸", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚µãƒ¼ãƒ“ã‚¹", "å€‰åº«", "è¼¸é€ã‚µãƒ¼ãƒ“ã‚¹",
    "é‹é€ä¼šç¤¾ä¼æ¥­ã®ã‚ªãƒ•ã‚£ã‚¹", "é‹é€ä¼šç¤¾"
]

# ===============================
# æ¥­ç¨®ãƒã‚¤ã‚ºé™¤å»ï¼ˆâ˜…è¿½åŠ ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
# ===============================
def clean_industry_noise(s: str) -> str:
    """æ¥­ç¨®ã‚«ãƒ©ãƒ ã«ç´›ã‚Œè¾¼ã‚€ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼/è©•ä¾¡/ä»¶æ•°ã€ãªã©ã®ãƒã‚¤ã‚ºã‚’é™¤å»ã€‚
    ä¾‹: '4.3(42)ãƒ»é£Ÿå“è£½é€ æ¥­è€…' -> 'é£Ÿå“è£½é€ æ¥­è€…'
        'ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—ãƒ»ç”£æ¥­ç”¨æ©Ÿå™¨è£½é€ æ¥­è€…' -> 'ç”£æ¥­ç”¨æ©Ÿå™¨è£½é€ æ¥­è€…'
        'ãƒ¬ãƒ“ãƒ¥ãƒ¼ ãƒ» é›»å­éƒ¨å“è£½é€ æ¥­è€…' -> 'é›»å­éƒ¨å“è£½é€ æ¥­è€…'
    """
    if not s:
        return s
    t = str(s)

    # å…ˆé ­ã®è©•ä¾¡ã‚¹ã‚³ã‚¢ + ä»¶æ•° ä¾‹: '4.7(123)ãƒ»', '4.7ï¼ˆ123ï¼‰ãƒ»'
    t = re.sub(r"^\s*\d+(?:\.\d+)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]\s*ãƒ»?\s*", "", t)

    # å…ˆé ­/ä¸­é–“ã®ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼ã€ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—ã€ã€ŒGoogle ã®ã‚¯ãƒã‚³ãƒŸã€ãªã©
    t = re.sub(r"(?:^|ãƒ»)\s*ãƒ¬ãƒ“ãƒ¥ãƒ¼(?:ãªã—)?\s*(?=ãƒ»|$)", "", t)
    t = re.sub(r"(?:^|ãƒ»)\s*(?:Google\s*ã®\s*ã‚¯ãƒã‚³ãƒŸ|å£ã‚³ãƒŸ|ã‚¯ãƒã‚³ãƒŸ)\s*(?=ãƒ»|$)", "", t)

    # åŒºåˆ‡ã‚Šã®æ•´å½¢
    t = re.sub(r"ãƒ»{2,}", "ãƒ»", t).strip("ãƒ» ").strip()
    return t

# ===============================
# å…±é€šæ•´å½¢ï¼ˆé›»è©±ã¯è§¦ã‚‰ãªã„ï¼‰
# ===============================
def clean_dataframe_except_phone(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€"]:
        df[c] = df[c].map(normalize_text)
    # â˜…æ¥­ç¨®ãƒã‚¤ã‚ºï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼/è©•ä¾¡ï¼‰ã ã‘ã‚’é™¤å»ã€‚ä»–åˆ—ã¯è§¦ã‚‰ãªã„
    df["æ¥­ç¨®"] = df["æ¥­ç¨®"].map(clean_industry_noise)
    return df.fillna("")

# ===============================
# UIï¼ˆNGãƒªã‚¹ãƒˆé¸æŠãƒ»æŠ½å‡ºæ–¹å¼ãƒ»æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå…¥åŠ›ï¼‰
# ===============================
st.markdown("### ğŸ›¡ï¸ ä½¿ç”¨ã™ã‚‹NGãƒªã‚¹ãƒˆã‚’é¸æŠ")
nglist_files = [f for f in os.listdir() if f.endswith(".xlsx") and "NGãƒªã‚¹ãƒˆ" in f]
nglist_options = ["ãªã—"] + [os.path.splitext(f)[0] for f in nglist_files]
selected_nglist = st.selectbox("NGãƒªã‚¹ãƒˆ", nglist_options, index=0, help="åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã€NGãƒªã‚¹ãƒˆã€œ.xlsxã€ã‚’æ¤œå‡ºã—ã¾ã™ã€‚1åˆ—ç›®=ä¼æ¥­åã€2åˆ—ç›®=é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰ã€‚")

st.markdown("### ğŸ§­ æŠ½å‡ºæ–¹æ³•ã‚’é¸æŠ")
profile = st.selectbox(
    "æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«",
    ["Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰", "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰", "æ—¥æœ¬å€‰åº«å”ä¼šãƒªã‚¹ãƒˆï¼ˆ4åˆ—å‹ï¼‰"]
)

st.markdown("### ğŸ­ æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ")
industry_option = st.radio("ã©ã®æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«è©²å½“ã—ã¾ã™ã‹ï¼Ÿ", ("è£½é€ æ¥­", "ç‰©æµæ¥­", "ãã®ä»–"))

st.markdown("### ğŸ§© ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—æ–¹æ³•ï¼ˆOSäº’æ›å¼·åŒ–ï¼‰")
template_source = st.radio(
    "template.xlsx ã®å–å¾—å…ƒ",
    ("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã® template.xlsx ã‚’ä½¿ã†ï¼ˆå¾“æ¥ï¼‰", "ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†"),
    index=0
)
template_upload = None
if template_source == "ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†":
    template_upload = st.file_uploader("template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], key="template_up")

uploaded_file = st.file_uploader("ğŸ“¤ æ•´å½¢å¯¾è±¡ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"])

# ===============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===============================
if uploaded_file:
    filename_no_ext = os.path.splitext(uploaded_file.name)[0]
    # xlsx ã¯å¸¸ã« openpyxl ã§èª­ã‚€ï¼ˆOSå·®ç•°å¯¾ç­–ï¼‰
    xl = pd.ExcelFile(uploaded_file, engine="openpyxl")

    # --- æŠ½å‡º ---
    # â‘  templateäº’æ›: ã€Œå…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼ã€ã‚·ãƒ¼ãƒˆãŒã‚ã‚Œã°æœ€å„ªå…ˆã§èª­ã¿å–ã‚Šï¼ˆé›»è©±ã¯åŸæ–‡ã®ã¾ã¾ï¼‰
    if "å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼" in xl.sheet_names:
        df_raw = pd.read_excel(xl, sheet_name="å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼", header=None, engine="openpyxl").fillna("")
        # è¡Œ1ãŒãƒ˜ãƒƒãƒ€ã€è¡Œ2ä»¥é™ãŒãƒ‡ãƒ¼ã‚¿ï¼ˆB:ä¼æ¥­å, C:æ¥­ç¨®, D:ä½æ‰€, E:é›»è©±ï¼‰
        df = pd.DataFrame({
            "ä¼æ¥­å": df_raw.iloc[1:, 1].astype(str),
            "æ¥­ç¨®": df_raw.iloc[1:, 2].astype(str),
            "ä½æ‰€": df_raw.iloc[1:, 3].astype(str),
            "é›»è©±ç•ªå·": df_raw.iloc[1:, 4].astype(str),   # â†é›»è©±ã¯åŸæ–‡ä¿æŒ
        })
    else:
        # â‘¡ ãã‚Œä»¥å¤–ã¯å¾“æ¥ã®3ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
        if profile == "Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰":
            df0 = pd.read_excel(uploaded_file, header=None, engine="openpyxl").fillna("")
            lines = df0.iloc[:, 0].tolist()
            df = extract_google_vertical(lines)
        elif profile == "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰":
            df0 = pd.read_excel(xl, header=None, engine="openpyxl").fillna("")
            df = extract_shigoto_arua(df0)
        else:
            df0 = pd.read_excel(xl, header=None, engine="openpyxl").fillna("")
            df = extract_warehouse_association(df0)

    # --- éé›»è©±åˆ—ã®ã¿æ­£è¦åŒ– ---
    df = clean_dataframe_except_phone(df)

    # --- æ¯”è¼ƒã‚­ãƒ¼ ---
    df["__company_canon"] = df["ä¼æ¥­å"].map(canonical_company_name)
    df["__digits"] = df["é›»è©±ç•ªå·"].map(phone_digits_only)

    # --- æ¥­ç¨®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆè£½é€ æ¥­ã®ã¿é™¤å¤–ãƒ«ãƒ¼ãƒ«é©ç”¨ï¼‰ ---
    removed_by_industry = 0
    if industry_option == "è£½é€ æ¥­":
        before = len(df)
        df = df[~df["æ¥­ç¨®"].isin(remove_exact)]
        if remove_partial:
            pat = "|".join(map(re.escape, remove_partial))
            df = df[~df["æ¥­ç¨®"].str.contains(pat, na=False)]
        removed_by_industry = before - len(df)
        st.warning(f"ğŸ­ è£½é€ æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼š{removed_by_industry}ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ")

    # --- NGç…§åˆï¼ˆä»»æ„ï¼‰ ---
    removal_logs = []
    company_removed = 0
    phone_removed = 0
    dup_removed = 0

    if selected_nglist != "ãªã—":
        ng_path = f"{selected_nglist}.xlsx"
        if not os.path.exists(ng_path):
            st.error(f"âŒ é¸æŠã•ã‚ŒãŸNGãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼š{ng_path}")
            st.stop()
        ng_df = pd.read_excel(ng_path, engine="openpyxl").fillna("")
        if ng_df.shape[1] < 1:
            st.error("âŒ NGãƒªã‚¹ãƒˆã¯å°‘ãªãã¨ã‚‚1åˆ—ï¼ˆä¼æ¥­åï¼‰ãŒå¿…è¦ã§ã™ã€‚2åˆ—ç›®ã«é›»è©±ç•ªå·ãŒã‚ã‚Œã°ç…§åˆã«åˆ©ç”¨ã—ã¾ã™ã€‚")
            st.stop()

        ng_df["__ng_company_canon"] = ng_df.iloc[:, 0].map(canonical_company_name)
        if ng_df.shape[1] >= 2:
            ng_df["__ng_digits"] = ng_df.iloc[:, 1].astype(str).map(phone_digits_only)
        else:
            ng_df["__ng_digits"] = ""

        ng_names = [n for n in ng_df["__ng_company_canon"].tolist() if n]
        ng_phones = set([d for d in ng_df["__ng_digits"].tolist() if d])

        # ä¼æ¥­åï¼ˆéƒ¨åˆ†ä¸€è‡´ãƒ»ç›¸äº’åŒ…å«ï¼‰
        before = len(df)
        hit_idx = []
        for idx, row in df.iterrows():
            c = row["__company_canon"]
            if not c:
                continue
            if any((n in c or c in n) for n in ng_names):
                removal_logs.append({
                    "reason": "ng-company",
                    "company": row["ä¼æ¥­å"],
                    "phone_raw": row["é›»è©±ç•ªå·"],
                    "match": c
                })
                hit_idx.append(idx)
        if hit_idx:
            df = df.drop(index=hit_idx)
        company_removed = before - len(df)

        # é›»è©±ç•ªå·digitsä¸€è‡´
        before = len(df)
        mask = df["__digits"].isin(ng_phones)
        if mask.any():
            for idx, row in df[mask].iterrows():
                removal_logs.append({
                    "reason": "ng-phone",
                    "company": row["ä¼æ¥­å"],
                    "phone_raw": row["é›»è©±ç•ªå·"],
                    "match": row["__digits"]
                })
            df = df[~mask]
        phone_removed = before - len(df)

    # --- é‡è¤‡ï¼ˆé›»è©±digitsï¼‰é™¤å» ---
    before = len(df)
    dup_mask = df["__digits"].ne("").astype(bool) & df["__digits"].duplicated(keep="first")
    if dup_mask.any():
        for idx, row in df[dup_mask].iterrows():
            removal_logs.append({
                "reason": "dup-phone",
                "company": row["ä¼æ¥­å"],
                "phone_raw": row["é›»è©±ç•ªå·"],
                "match": row["__digits"]
            })
        df = df[~dup_mask]
    dup_removed = before - len(df)

    # --- ç©ºè¡Œã®é™¤å» ---
    df = df[~((df["ä¼æ¥­å"] == "") & (df["æ¥­ç¨®"] == "") & (df["ä½æ‰€"] == "") & (df["é›»è©±ç•ªå·"] == ""))].reset_index(drop=True)

    # --- ç”»é¢è¡¨ç¤ºï¼ˆç·¨é›†å¯ï¼‰ ---
    st.success(f"âœ… æ•´å½¢å®Œäº†ï¼š{len(df)}ä»¶ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
    edited = st.data_editor(
        df[["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"]],
        use_container_width=True,
        num_rows="fixed",
        column_config={
            "ä¼æ¥­å": st.column_config.TextColumn(required=True),
            "æ¥­ç¨®": st.column_config.TextColumn(),
            "ä½æ‰€": st.column_config.TextColumn(),
            "é›»è©±ç•ªå·": st.column_config.TextColumn(
                help="åŸæ–‡ã®é…åˆ—ã‚’ä¿æŒã€‚å¿…è¦ãªã‚‰ã“ã“ã§æ‰‹å‹•ä¿®æ­£ã—ã€ã“ã®å†…å®¹ã§ç¢ºå®šã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
            ),
        },
        key="editable_preview",
    )

    if st.button("âœ… ã“ã®å†…å®¹ã§ç¢ºå®šï¼ˆåæ˜ ï¼‰"):
        df["ä¼æ¥­å"], df["æ¥­ç¨®"], df["ä½æ‰€"], df["é›»è©±ç•ªå·"] = (
            edited["ä¼æ¥­å"],
            edited["æ¥­ç¨®"],
            edited["ä½æ‰€"],
            edited["é›»è©±ç•ªå·"],
        )
        # å†è¨ˆç®—ï¼ˆé‡è¤‡ç­‰ã®å¾Œç¶šæ“ä½œã«å‚™ãˆã¦digitsã‚’æ›´æ–°ï¼‰
        df["__digits"] = df["é›»è©±ç•ªå·"].map(phone_digits_only)
        st.success("ç·¨é›†å†…å®¹ã‚’åæ˜ ã—ã¾ã—ãŸã€‚å‡ºåŠ›ã¯ã“ã®è¡¨è¨˜ã®ã¾ã¾ã§ã™ã€‚")

    # --- ã‚µãƒãƒªãƒ¼ï¼†å‰Šé™¤ãƒ­ã‚°DL ---
    with st.expander("ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼ï¼ˆè©³ç´°ï¼‰"):
        st.markdown(
            f"- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é™¤å¤–ï¼ˆè£½é€ æ¥­ å®Œå…¨ä¸€è‡´ï¼‹ä¸€éƒ¨éƒ¨åˆ†ä¸€è‡´ï¼‰: **{removed_by_industry}** ä»¶\n"
            f"- NGï¼ˆä¼æ¥­å éƒ¨åˆ†ä¸€è‡´ï¼‰å‰Šé™¤: **{company_removed}** ä»¶\n"
            f"- NGï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{phone_removed}** ä»¶\n"
            f"- é‡è¤‡ï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{dup_removed}** ä»¶\n"
        )
        if removal_logs:
            log_df = pd.DataFrame(removal_logs)
            st.dataframe(log_df.head(300), use_container_width=True)
            csv_bytes = log_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button("ğŸ§¾ å‰Šé™¤ãƒ­ã‚°ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_bytes, file_name="removal_logs.csv", mime="text/csv")

    # ===============================
    # template.xlsx ã¸æ›¸ãè¾¼ã¿ï¼ˆOSäº’æ›å¼·åŒ–ï¼‰
    # ===============================
    # 1) ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸ template.xlsx ã‚’å„ªå…ˆ
    wb = None
    if template_upload is not None:
        try:
            buf = io.BytesIO(template_upload.read())
            wb = load_workbook(buf)
        except Exception as e:
            st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸ template.xlsx ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()
    else:
        # 2) ã‚¹ã‚¯ãƒªãƒ—ãƒˆç›¸å¯¾ãƒ‘ã‚¹ã§è§£æ±ºï¼ˆä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå·®ã‚’å¸åï¼‰
        app_dir = Path(__file__).resolve().parent
        template_path = app_dir / "template.xlsx"
        if not template_path.exists():
            st.error(f"âŒ template.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆæœŸå¾…ãƒ‘ã‚¹: {template_path}ï¼‰ã€‚"
                     "ã€ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†ã€ã‚’é¸ã¶ã‹ã€"
                     "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        try:
            wb = load_workbook(template_path)
        except Exception as e:
            st.error(f"âŒ template.xlsx ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()

    if "å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼" not in wb.sheetnames:
        st.error("âŒ template.xlsx ã«ã€å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼ã€ã¨ã„ã†ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
        st.stop()

    sheet = wb["å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼"]

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ï¼ˆ2è¡Œç›®ä»¥é™ã®Bã€œEï¼‰ã¨å¡—ã‚Šã‚’ã‚¯ãƒªã‚¢
    for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row):
        for cell in row[1:5]:  # B(1)ã€œE(4)
            cell.value = None
            cell.fill = PatternFill(fill_type=None)

    # ç‰©æµãƒã‚¤ãƒ©ã‚¤ãƒˆï¼ˆæ¥­ç¨®ã«ç‰¹å®šèªãŒå«ã¾ã‚Œã‚‹å ´åˆã€Cåˆ—ã‚’èµ¤ãï¼‰
    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
    def is_logi(val: str) -> bool:
        v = (val or "").strip()
        return any(word in v for word in highlight_partial)

    # ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ï¼ˆB=ä¼æ¥­å, C=æ¥­ç¨®, D=ä½æ‰€, E=é›»è©±ï¼‰
    for idx, row in df.iterrows():
        r = idx + 2
        sheet.cell(row=r, column=2, value=row["ä¼æ¥­å"])
        sheet.cell(row=r, column=3, value=row["æ¥­ç¨®"])
        sheet.cell(row=r, column=4, value=row["ä½æ‰€"])
        sheet.cell(row=r, column=5, value=row["é›»è©±ç•ªå·"])
        if industry_option == "ç‰©æµæ¥­" and is_logi(row["æ¥­ç¨®"]):
            sheet.cell(row=r, column=3).fill = red_fill

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    output = io.BytesIO()
    wb.save(output)
    output.seek(0)
    st.download_button(
        label="ğŸ“¥ æ•´å½¢æ¸ˆã¿ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆtemplate.xlsx åæ˜ ï¼‰",
        data=output,
        file_name=f"{filename_no_ext}ãƒªã‚¹ãƒˆ.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

else:
    st.info("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚NGãƒªã‚¹ãƒˆxlsxã¯åŒãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ãã‹ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
