import streamlit as st
import pandas as pd
import re
import unicodedata
import io
import os
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# Streamlitè¨­å®š
# ===============================
st.set_page_config(page_title="G-Change Next", layout="wide")
st.title("ğŸš— G-Change Nextï½œä¼æ¥­æƒ…å ±æ•´å½¢ï¼†NGé™¤å¤–ãƒ„ãƒ¼ãƒ«ï¼ˆVer5.3 åŸæ–‡é›»è©±ä¿æŒï¼‹èª¤æ¤œå‡ºé˜²æ­¢ï¼‹NGç…§åˆï¼‰")

# ===============================
# ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
# ===============================
def nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s)

def normalize_text(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).replace("\u3000", " ").replace("\xa0", " ")
    s = re.sub(r'[âˆ’â€“â€”â€•ãƒ¼]', '-', s)
    return nfkc(s).strip()

def clean_address(address: str) -> str:
    address = normalize_text(address)
    return address.strip()

def extract_industry(line: str) -> str:
    return normalize_text(line)

# ===============================
# ä¼æ¥­åæ­£è¦åŒ–ï¼ˆNGç…§åˆç”¨ï¼‰
# ===============================
COMPANY_SUFFIXES = ["æ ªå¼ä¼šç¤¾", "(æ ª)", "ï¼ˆæ ªï¼‰", "æœ‰é™ä¼šç¤¾", "(æœ‰)", "ï¼ˆæœ‰ï¼‰", "åˆåŒä¼šç¤¾"]
def canonical_company_name(name: str) -> str:
    s = normalize_text(name)
    for suf in sorted(COMPANY_SUFFIXES, key=len, reverse=True):
        s = s.replace(suf, "")
    s = re.sub(r"[\s\-ãƒ»/,.Â·ï½¥\(\)ï¼ˆï¼‰ã€ã€‘ï¼†&ï¼‹+_|]", "", s)
    return s

# ===============================
# é›»è©±ç•ªå·å‡¦ç†ï¼ˆåŸæ–‡ä¿æŒï¼‰
# ===============================
HYPHENS = "-â€’â€“â€”â€•âˆ’ï¼ãƒ¼â€ï¹£\u2011"
HYPHENS_CLASS = re.escape(HYPHENS)

# é›»è©±ç•ªå·å€™è£œæŠ½å‡ºï¼ˆèª¤æ¤œå‡ºé˜²æ­¢ï¼‰
# 8æ–‡å­—ä»¥ä¸Šã®æ•°å­—ï¼‹ãƒã‚¤ãƒ•ãƒ³/ç©ºç™½ã®å¡Šã‚’å€™è£œåŒ–
CANDIDATE_RE = re.compile(rf"[+]?\d(?:[\d{HYPHENS_CLASS}\s]{{6,}})\d")

def pick_phone_token_raw(line: str) -> str:
    """1è¡Œã‹ã‚‰é›»è©±ç•ªå·ã‚‰ã—ã„æ–‡å­—åˆ—ã‚’æŠ½å‡ºã€‚
       digits é•·ãŒ 9ã€œ11 ä»¥å¤–ã¯ä¸æ¡ç”¨ã€‚åŸæ–‡è¡¨è¨˜ï¼ˆãƒã‚¤ãƒ•ãƒ³ä½ç½®ï¼‰ã‚’ãã®ã¾ã¾è¿”ã™ã€‚"""
    if not line:
        return ""
    s = unicodedata.normalize("NFKC", str(line))
    raw_cands = CANDIDATE_RE.findall(s)
    cands = []
    for token in raw_cands:
        tok = token.strip()
        if ":" in tok:           # æ™‚åˆ»æ··å…¥ãªã©ã¯é™¤å¤–
            continue
        digits = re.sub(r"\D", "", tok)
        if not (9 <= len(digits) <= 11):
            continue             # 11-10 ã®ã‚ˆã†ãªçŸ­ã„å¡Šã¯é™¤å¤–
        if not (digits.startswith("0") or digits.startswith("81")):
            continue             # å›½å†…å…ˆé ­0 or å›½ç•ªå·81ã®ã¿è¨±å¯
        score = (len(digits), tok.count("-"))  # é•·ã„digitsï¼†ãƒã‚¤ãƒ•ãƒ³å¤šã„ï¼é›»è©±ã£ã½ã„
        cands.append((score, tok))
    if not cands:
        return ""
    cands.sort(key=lambda x: x[0], reverse=True)
    return cands[0][1]

def phone_digits_only(s: str) -> str:
    """å†…éƒ¨ç…§åˆç”¨ã«æ•°å­—ã ã‘æŠ½å‡º"""
    return re.sub(r"\D", "", str(s or ""))

# ===============================
# Googleæ¤œç´¢ãƒªã‚¹ãƒˆå½¢å¼ï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹ï¼‰
# ===============================
def extract_google_vertical(lines):
    results = []
    rows = [str(l) for l in lines if str(l).strip() != ""]
    for i, line in enumerate(rows):
        ph_raw = pick_phone_token_raw(line)
        if ph_raw:
            phone = ph_raw  # åŸæ–‡ä¿æŒ
            address = rows[i - 1] if i - 1 >= 0 else ""
            industry = extract_industry(rows[i - 2]) if i - 2 >= 0 else ""
            company = rows[i - 3] if i - 3 >= 0 else ""
            results.append([company, industry, clean_address(address), phone])
    return pd.DataFrame(results, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# ===============================
# ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯å½¢å¼ï¼ˆç¸¦ç©ã¿ï¼‰
# ===============================
def extract_shigoto_arua(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.copy()
    if df.columns.size > 2:
        df = df.iloc[:, :2]
    df.columns = ["col0", "col1"]
    df = df.fillna("")
    current = {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""}
    out = []

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], current["æ¥­ç¨®"], current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""})

    for _, row in df.iterrows():
        k, v = str(row["col0"]), str(row["col1"])
        if k in ["ä½æ‰€", "æ‰€åœ¨åœ°", "æœ¬ç¤¾æ‰€åœ¨åœ°"]:
            current["ä½æ‰€"] = clean_address(v)
        elif k in ["é›»è©±", "é›»è©±ç•ªå·", "TEL", "Tel", "tel"]:
            current["é›»è©±ç•ªå·"] = v  # åŸæ–‡ä¿æŒ
        elif k in ["æ¥­ç¨®", "äº‹æ¥­å†…å®¹", "ç”£æ¥­åˆ†é¡", "è£½é€ æ¥­ç¨®"]:
            current["æ¥­ç¨®"] = extract_industry(v)
        elif k and not v:
            if current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = k
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# ===============================
# æ—¥æœ¬å€‰åº«å”ä¼šå½¢å¼ï¼ˆ4åˆ—ï¼‰
# ===============================
def extract_warehouse_association(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.fillna("")
    if df.shape[1] < 2:
        return pd.DataFrame(columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])
    while df.shape[1] < 4:
        df[f"__pad{df.shape[1]}"] = ""
    df = df.iloc[:, :4]
    df.columns = ["c0", "c1", "c2", "c3"]

    tel_re = re.compile(r"(?:TEL|Tel|tel)\s*([0-9ï¼-ï¼™\-ãƒ¼ï¼\s]+)")
    out, current = [], {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()}

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], "ãƒ»".join(current["æ¥­ç¨®_set"]), current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()})

    for _, r in df.iterrows():
        if r["c0"]:
            if current["ä¼æ¥­å"] and r["c0"] != current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = r["c0"]
        if r["c1"]:
            current["ä½æ‰€"] = clean_address(r["c1"])
        if r["c2"]:
            m = tel_re.search(r["c2"])
            if m:
                current["é›»è©±ç•ªå·"] = m.group(1).strip()  # åŸæ–‡ä¿æŒ
        if r["c3"]:
            current["æ¥­ç¨®_set"].add(extract_industry(r["c3"]))
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# ===============================
# å…±é€šæ•´å½¢ï¼ˆé›»è©±ã¯è§¦ã‚‰ãªã„ï¼‰
# ===============================
def clean_dataframe_except_phone(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€"]:
        df[c] = df[c].map(normalize_text)
    return df.fillna("")

# ===============================
# UIï¼šNGãƒªã‚¹ãƒˆé¸æŠã‚’å¾©æ´»
# ===============================
st.markdown("### ğŸ›¡ï¸ ä½¿ç”¨ã™ã‚‹NGãƒªã‚¹ãƒˆã‚’é¸æŠ")
nglist_files = [f for f in os.listdir() if f.endswith(".xlsx") and "NGãƒªã‚¹ãƒˆ" in f]
nglist_options = ["ãªã—"] + [os.path.splitext(f)[0] for f in nglist_files]
selected_nglist = st.selectbox("NGãƒªã‚¹ãƒˆ", nglist_options, index=0, help="åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã€NGãƒªã‚¹ãƒˆã€œ.xlsxã€ã‚’æ¤œå‡ºã—ã¾ã™ã€‚1åˆ—ç›®=ä¼æ¥­åã€2åˆ—ç›®=é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰ã€‚")

# ===============================
# å…¥åŠ›UI
# ===============================
st.markdown("### ğŸ“¤ æ•´å½¢å¯¾è±¡ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
profile = st.selectbox(
    "æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«",
    ["Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰", "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰", "æ—¥æœ¬å€‰åº«å”ä¼šãƒªã‚¹ãƒˆï¼ˆ4åˆ—å‹ï¼‰"]
)
uploaded_file = st.file_uploader("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ", type=["xlsx"])

# ===============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===============================
if uploaded_file:
    xl = pd.ExcelFile(uploaded_file)
    # --- æŠ½å‡º ---
    if profile == "Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰":
        df0 = pd.read_excel(uploaded_file, header=None).fillna("")
        lines = df0.iloc[:, 0].tolist()
        df = extract_google_vertical(lines)
    elif profile == "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰":
        df0 = pd.read_excel(xl, header=None).fillna("")
        df = extract_shigoto_arua(df0)
    else:
        df0 = pd.read_excel(xl, header=None).fillna("")
        df = extract_warehouse_association(df0)

    # --- éé›»è©±åˆ—ã®ã¿æ­£è¦åŒ– ---
    df = clean_dataframe_except_phone(df)

    # --- æ¯”è¼ƒã‚­ãƒ¼ ---
    df["__company_canon"] = df["ä¼æ¥­å"].map(canonical_company_name)
    df["__digits"] = df["é›»è©±ç•ªå·"].map(phone_digits_only)

    # --- NGç…§åˆï¼ˆä»»æ„ï¼‰ï¼† é‡è¤‡å‰Šé™¤ ---
    removal_logs = []
    company_removed = 0
    phone_removed = 0
    dup_removed = 0

    if selected_nglist != "ãªã—":
        ng_path = f"{selected_nglist}.xlsx"
        if not os.path.exists(ng_path):
            st.error(f"âŒ é¸æŠã•ã‚ŒãŸNGãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼š{ng_path}")
            st.stop()
        ng_df = pd.read_excel(ng_path).fillna("")
        if ng_df.shape[1] < 1:
            st.error("âŒ NGãƒªã‚¹ãƒˆã¯å°‘ãªãã¨ã‚‚1åˆ—ï¼ˆä¼æ¥­åï¼‰ãŒå¿…è¦ã§ã™ã€‚2åˆ—ç›®ã«é›»è©±ç•ªå·ãŒã‚ã‚Œã°ç…§åˆã«åˆ©ç”¨ã—ã¾ã™ã€‚")
            st.stop()

        ng_df["__ng_company_canon"] = ng_df.iloc[:, 0].map(canonical_company_name)
        if ng_df.shape[1] >= 2:
            ng_df["__ng_digits"] = ng_df.iloc[:, 1].astype(str).map(phone_digits_only)
        else:
            ng_df["__ng_digits"] = ""

        ng_names = [n for n in ng_df["__ng_company_canon"].tolist() if n]
        ng_phones = set([d for d in ng_df["__ng_digits"].tolist() if d])

        # ä¼æ¥­åï¼ˆéƒ¨åˆ†ä¸€è‡´ãƒ»ç›¸äº’åŒ…å«ï¼‰
        before = len(df)
        hit_idx = []
        for idx, row in df.iterrows():
            c = row["__company_canon"]
            if not c:
                continue
            if any((n in c or c in n) for n in ng_names):
                removal_logs.append({
                    "reason": "ng-company",
                    "company": row["ä¼æ¥­å"],
                    "phone_raw": row["é›»è©±ç•ªå·"],
                    "match": c
                })
                hit_idx.append(idx)
        if hit_idx:
            df = df.drop(index=hit_idx)
        company_removed = before - len(df)

        # é›»è©±ç•ªå·digitsä¸€è‡´
        before = len(df)
        mask = df["__digits"].isin(ng_phones)
        if mask.any():
            for idx, row in df[mask].iterrows():
                removal_logs.append({
                    "reason": "ng-phone",
                    "company": row["ä¼æ¥­å"],
                    "phone_raw": row["é›»è©±ç•ªå·"],
                    "match": row["__digits"]
                })
            df = df[~mask]
        phone_removed = before - len(df)

    # é‡è¤‡ï¼ˆé›»è©±digitsï¼‰é™¤å»
    before = len(df)
    dup_mask = df["__digits"].ne("").astype(bool) & df["__digits"].duplicated(keep="first")
    if dup_mask.any():
        for idx, row in df[dup_mask].iterrows():
            removal_logs.append({
                "reason": "dup-phone",
                "company": row["ä¼æ¥­å"],
                "phone_raw": row["é›»è©±ç•ªå·"],
                "match": row["__digits"]
            })
        df = df[~dup_mask]
    dup_removed = before - len(df)

    # --- è¡¨ç¤ºï¼ˆç·¨é›†å¯ï¼‰ ---
    st.success(f"âœ… æ•´å½¢å®Œäº†ï¼š{len(df)}ä»¶ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
    edited = st.data_editor(
        df[["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"]],
        use_container_width=True,
        num_rows="fixed",
        column_config={
            "ä¼æ¥­å": st.column_config.TextColumn(required=True),
            "æ¥­ç¨®": st.column_config.TextColumn(),
            "ä½æ‰€": st.column_config.TextColumn(),
            "é›»è©±ç•ªå·": st.column_config.TextColumn(
                help="åŸæ–‡ã®é…åˆ—ã‚’ä¿æŒã€‚å¿…è¦ãªã‚‰ã“ã“ã§æ‰‹å‹•ä¿®æ­£ã—ã€ã“ã®å†…å®¹ã§ç¢ºå®šã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚"
            ),
        },
        key="editable_preview",
    )

    if st.button("âœ… ã“ã®å†…å®¹ã§ç¢ºå®šï¼ˆåæ˜ ï¼‰"):
        df["ä¼æ¥­å"], df["æ¥­ç¨®"], df["ä½æ‰€"], df["é›»è©±ç•ªå·"] = (
            edited["ä¼æ¥­å"],
            edited["æ¥­ç¨®"],
            edited["ä½æ‰€"],
            edited["é›»è©±ç•ªå·"],
        )
        # å†è¨ˆç®—ï¼ˆé‡è¤‡ç­‰ã®å¾Œç¶šæ“ä½œã«å‚™ãˆã¦digitsã‚’æ›´æ–°ï¼‰
        df["__digits"] = df["é›»è©±ç•ªå·"].map(phone_digits_only)
        st.success("ç·¨é›†å†…å®¹ã‚’åæ˜ ã—ã¾ã—ãŸã€‚å‡ºåŠ›ã¯ã“ã®è¡¨è¨˜ã®ã¾ã¾ã§ã™ã€‚")

    # --- ã‚µãƒãƒªãƒ¼ï¼†å‰Šé™¤ãƒ­ã‚°DL ---
    with st.expander("ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼ï¼ˆè©³ç´°ï¼‰"):
        st.markdown(
            f"- NGï¼ˆä¼æ¥­å éƒ¨åˆ†ä¸€è‡´ï¼‰å‰Šé™¤: **{company_removed}** ä»¶\n"
            f"- NGï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{phone_removed}** ä»¶\n"
            f"- é‡è¤‡ï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{dup_removed}** ä»¶\n"
        )
        if removal_logs:
            log_df = pd.DataFrame(removal_logs)
            st.dataframe(log_df.head(200), use_container_width=True)
            csv_bytes = log_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button("ğŸ§¾ å‰Šé™¤ãƒ­ã‚°ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv_bytes, file_name="removal_logs.csv", mime="text/csv")

    # --- Excelå‡ºåŠ›ï¼ˆç°¡æ˜“ï¼šå˜ä¸€ã‚·ãƒ¼ãƒˆï¼‰ ---
    out = io.BytesIO()
    df_out = df.drop(columns=["__company_canon", "__digits"], errors="ignore")
    with pd.ExcelWriter(out, engine="openpyxl") as writer:
        df_out.to_excel(writer, index=False, sheet_name="å‡ºåŠ›")
    out.seek(0)
    st.download_button("ğŸ“¥ æ•´å½¢æ¸ˆã¿ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=out, file_name="æ•´å½¢æ¸ˆã¿ãƒªã‚¹ãƒˆ.xlsx")

else:
    st.info("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚NGãƒªã‚¹ãƒˆxlsxã‚’åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ãã¨é¸æŠã§ãã¾ã™ã€‚")
