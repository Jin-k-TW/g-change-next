import streamlit as st
import pandas as pd
import re
import unicodedata
import io
import os
from pathlib import Path
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰èªè¨¼ï¼‰
# ===============================
def check_password():
    """st.secrets['password'] ã¨ä¸€è‡´ã™ã‚‹ã‹ã‚’ç¢ºèªã™ã‚‹ç°¡æ˜“ãƒ­ã‚°ã‚¤ãƒ³"""
    def password_entered():
        """ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã«å…¥åŠ›ã•ã‚ŒãŸãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’æ¤œè¨¼"""
        if "password" not in st.secrets:
            st.session_state["password_correct"] = False
            st.session_state["password_error"] = "ã‚µãƒ¼ãƒãƒ¼å´ã«ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ç®¡ç†è€…ã«ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            return

        if st.session_state["password"] == st.secrets["password"]:
            st.session_state["password_correct"] = True
            st.session_state.pop("password", None)
            st.session_state.pop("password_error", None)
        else:
            st.session_state["password_correct"] = False
            st.session_state["password_error"] = "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒé•ã„ã¾ã™ã€‚ã‚‚ã†ä¸€åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"

    if "password_correct" not in st.session_state:
        st.session_state["password_correct"] = False

    if not st.session_state["password_correct"]:
        st.title("ğŸ” G-Change Next ãƒ­ã‚°ã‚¤ãƒ³")
        st.text_input(
            "ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            type="password",
            on_change=password_entered,
            key="password",
        )
        if "password_error" in st.session_state and st.session_state["password_error"]:
            st.error(st.session_state["password_error"])
        return False

    return True

# ===============================
# Streamlitè¨­å®š
# ===============================
st.set_page_config(page_title="G-Change Next", layout="wide")

if not check_password():
    st.stop()

st.title("ğŸš— G-Change Nextï½œä¼æ¥­æƒ…å ±æ•´å½¢ï¼†NGé™¤å¤–ãƒ„ãƒ¼ãƒ«ï¼ˆVer6.3 è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼‹ç¢ºå®šãƒœã‚¿ãƒ³çœç•¥ç‰ˆï¼‰")

# ===============================
# ãƒ†ã‚­ã‚¹ãƒˆæ­£è¦åŒ–
# ===============================
def nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s)

def normalize_text(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).replace("\u3000", " ").replace("\xa0", " ")
    s = re.sub(r'[âˆ’â€“â€”â€•ãƒ¼]', '-', s)
    return nfkc(s).strip()

def clean_address(address: str) -> str:
    address = normalize_text(address)
    return address.strip()

def extract_industry(line: str) -> str:
    return normalize_text(line)

# ===============================
# ä¼æ¥­åæ­£è¦åŒ–ï¼ˆNGç…§åˆç”¨ï¼‰
# ===============================
COMPANY_SUFFIXES = ["æ ªå¼ä¼šç¤¾", "(æ ª)", "ï¼ˆæ ªï¼‰", "æœ‰é™ä¼šç¤¾", "(æœ‰)", "ï¼ˆæœ‰ï¼‰", "åˆåŒä¼šç¤¾"]
def canonical_company_name(name: str) -> str:
    s = normalize_text(name)
    for suf in sorted(COMPANY_SUFFIXES, key=len, reverse=True):
        s = s.replace(suf, "")
    s = re.sub(r"[\s\-ãƒ»/,.Â·ï½¥\(\)ï¼ˆï¼‰ã€ã€‘ï¼†&ï¼‹+_|]", "", s)
    return s

# ===============================
# é›»è©±ç•ªå·å‡¦ç†ï¼ˆåŸæ–‡ä¿æŒï¼‰
# ===============================
HYPHENS = "-â€’â€“â€”â€•âˆ’ï¼ãƒ¼â€ï¹£\u2011"
HYPHENS_CLASS = re.escape(HYPHENS)

CANDIDATE_RE = re.compile(rf"[+]?\d(?:[\d{HYPHENS_CLASS}\s]{{6,}})\d")

def pick_phone_token_raw(line: str) -> str:
    """1è¡Œã‹ã‚‰é›»è©±ç•ªå·ã‚‰ã—ã„æ–‡å­—åˆ—ã‚’æŠ½å‡ºã€‚digits é•·ãŒ 9ã€œ11 ä»¥å¤–ã¯ä¸æ¡ç”¨ã€‚"""
    if not line:
        return ""
    s = unicodedata.normalize("NFKC", str(line))
    raw_cands = CANDIDATE_RE.findall(s)
    cands = []
    for token in raw_cands:
        tok = token.strip()
        if ":" in tok:
            continue
        digits = re.sub(r"\D", "", tok)
        if not (9 <= len(digits) <= 11):
            continue
        if not (digits.startswith("0") or digits.startswith("81")):
            continue
        score = (len(digits), tok.count("-"))
        cands.append((score, tok))
    if not cands:
        return ""
    cands.sort(key=lambda x: x[0], reverse=True)
    return cands[0][1]

def phone_digits_only(s: str) -> str:
    return re.sub(r"\D", "", str(s or ""))

# ===============================
# ä½æ‰€åˆ¤å®šï¼‹æ¥­ç¨®åˆ†å‰²ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¼·åŒ–ç‰ˆï¼‰
# ===============================

JAPAN_PREFS = [
    "åŒ—æµ·é“",
    "é’æ£®çœŒ","å²©æ‰‹çœŒ","å®®åŸçœŒ","ç§‹ç”°çœŒ","å±±å½¢çœŒ","ç¦å³¶çœŒ",
    "èŒ¨åŸçœŒ","æ ƒæœ¨çœŒ","ç¾¤é¦¬çœŒ","åŸ¼ç‰çœŒ","åƒè‘‰çœŒ","æ±äº¬éƒ½","ç¥å¥ˆå·çœŒ",
    "æ–°æ½ŸçœŒ","å¯Œå±±çœŒ","çŸ³å·çœŒ","ç¦äº•çœŒ","å±±æ¢¨çœŒ","é•·é‡çœŒ",
    "å²é˜œçœŒ","é™å²¡çœŒ","æ„›çŸ¥çœŒ","ä¸‰é‡çœŒ",
    "æ»‹è³€çœŒ","äº¬éƒ½åºœ","å¤§é˜ªåºœ","å…µåº«çœŒ","å¥ˆè‰¯çœŒ","å’Œæ­Œå±±çœŒ",
    "é³¥å–çœŒ","å³¶æ ¹çœŒ","å²¡å±±çœŒ","åºƒå³¶çœŒ","å±±å£çœŒ",
    "å¾³å³¶çœŒ","é¦™å·çœŒ","æ„›åª›çœŒ","é«˜çŸ¥çœŒ",
    "ç¦å²¡çœŒ","ä½è³€çœŒ","é•·å´çœŒ","ç†Šæœ¬çœŒ","å¤§åˆ†çœŒ","å®®å´çœŒ","é¹¿å…å³¶çœŒ","æ²–ç¸„çœŒ",
]

def split_industry_and_address(line: str):
    """
    1ã‚»ãƒ«ã«ã€Œæ¥­ç¨® + ä½æ‰€ã€ãŒå…¥ã£ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã‚’æƒ³å®šã€‚
    å·¦å´ = æ¥­ç¨®, å³å´ = ä½æ‰€ ã¨ã—ã¦åˆ†å‰²ã™ã‚‹ã€‚

    ä½æ‰€ã®é–‹å§‹ä½ç½®ã¯æ¬¡ã®é †ã§æ¢ã™ï¼š
      1) éƒ½é“åºœçœŒå
      2) ã€Œå¸‚ / åŒº / éƒ¡ / ç”º / æ‘ã€ãªã©
      3) éƒµä¾¿ç•ªå· (123-4567 / ã€’123-4567)
      4) æœ€åˆã®æ•°å­—
    è¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ (\"\", \"\") ã‚’è¿”ã—ã¦æ—§ãƒ­ã‚¸ãƒƒã‚¯ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚
    """
    if not line:
        return ("", "")

    s = normalize_text(line)

    addr_pos = None

    # 1) éƒ½é“åºœçœŒå
    for pref in JAPAN_PREFS:
        idx = s.find(pref)
        if idx != -1 and (addr_pos is None or idx < addr_pos):
            addr_pos = idx

    # 2) å¸‚/åŒº/éƒ¡/ç”º/æ‘ ãªã©ï¼ˆéƒ½é“åºœçœŒãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã¨ãï¼‰
    if addr_pos is None:
        m_city = re.search(r".{0,5}(å¸‚|åŒº|éƒ¡|ç”º|æ‘)", s)
        if m_city:
            addr_pos = max(0, m_city.start())

    # 3) éƒµä¾¿ç•ªå· (123-4567 / ã€’123-4567)
    if addr_pos is None:
        m_zip = re.search(r"ã€’?\d{3}-\d{4}", s)
        if m_zip:
            addr_pos = m_zip.start()

    # 4) æœ€åˆã®æ•°å­—ï¼ˆç•ªåœ°ãƒ»ä¸ç›®ãªã©ï¼‰
    if addr_pos is None:
        m_num = re.search(r"\d", s)
        if m_num:
            addr_pos = m_num.start()

    # ãã‚Œã§ã‚‚è¦‹ã¤ã‹ã‚‰ãªã„ â†’ ä½æ‰€ã¨ã¯åˆ¤æ–­ã—ãªã„ï¼ˆæ—§ãƒ­ã‚¸ãƒƒã‚¯ã«ä»»ã›ã‚‹ï¼‰
    if addr_pos is None:
        return ("", "")

    industry = s[:addr_pos].strip(" ãƒ»:ï¼šã€€")
    address  = s[addr_pos:].strip()

    # ä½æ‰€å€™è£œãŒã‚ã¾ã‚Šã«ä½æ‰€ã£ã½ããªã„å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if not address:
        return ("", "")

    # å¸‚åŒºç”ºæ‘ or æ•°å­—ãŒä¸€åˆ‡ç„¡ã„å ´åˆã¯ä½æ‰€ã¨ã¿ãªã•ãªã„
    if not re.search(r"[å¸‚åŒºéƒ¡ç”ºæ‘]", address) and not re.search(r"\d", address):
        return ("", "")

    return (industry, address)

# ===============================
# æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ3æ–¹å¼ï¼‰
# ===============================

# 1) Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹ï¼‰
def extract_google_vertical(lines):
    """
    Googleãƒãƒƒãƒ—ç¸¦å‹ãƒªã‚¹ãƒˆç”¨ã€‚
    - ãƒ‘ã‚¿ãƒ¼ãƒ³Aï¼ˆæ–°ï¼‰ï¼šé›»è©±è¡Œã®1ã¤ä¸Šã«ã€Œæ¥­ç¨®+ä½æ‰€ã€ã®ã‚»ãƒ«ã€ãã®ä¸Šã«ä¼æ¥­å
    - ãƒ‘ã‚¿ãƒ¼ãƒ³Bï¼ˆæ—§ï¼‰ï¼šé›»è©±è¡Œã®1ã¤ä¸Šã«ä½æ‰€ã€2ã¤ä¸Šã«æ¥­ç¨®ã€3ã¤ä¸Šã«ä¼æ¥­å
    ã®ä¸¡æ–¹ã‚’è‡ªå‹•ã§åˆ¤å®šã—ã¦å‡¦ç†ã™ã‚‹ã€‚
    """
    results = []
    rows = [str(l) for l in lines if str(l).strip() != ""]

    for i, line in enumerate(rows):
        ph_raw = pick_phone_token_raw(line)
        if not ph_raw:
            continue

        phone = ph_raw
        company = ""
        industry = ""
        address = ""

        # ç›´ä¸Šã®è¡Œã‚’æ¥­ç¨®+ä½æ‰€ã‚»ãƒ«ã¨ã—ã¦è©¦ã™ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³Aï¼‰
        mid = rows[i - 1] if i - 1 >= 0 else ""
        ind_a, addr_a = split_industry_and_address(mid)

        if addr_a:  # ä½æ‰€ãŒåˆ¤å®šã§ããŸ â†’ æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³
            address = clean_address(addr_a)
            industry = ind_a  # ç©ºãªã‚‰ã‚ã¨ã§è£œå®Œ
            company = rows[i - 2] if i - 2 >= 0 else ""

            # æ¥­ç¨®ãŒç©ºãªã‚‰ã€ã•ã‚‰ã«1ã¤ä¸Šã®è¡Œã‚’æ¥­ç¨®ã¨ã—ã¦è£œå®Œã—ã¦ã¿ã‚‹
            if not industry and i - 2 >= 0:
                industry = extract_industry(rows[i - 2])

        else:
            # æ—§ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            address = clean_address(mid)
            industry = extract_industry(rows[i - 2]) if i - 2 >= 0 else ""
            company = rows[i - 3] if i - 3 >= 0 else ""

        results.append([company, industry, address, phone])

    return pd.DataFrame(results, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# 2) ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯ï¼ˆç¸¦ç©ã¿ï¼‰
def extract_shigoto_arua(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.copy()
    if df.columns.size > 2:
        df = df.iloc[:, :2]
    df.columns = ["col0", "col1"]
    df = df.fillna("")
    current = {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""}
    out = []

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], current["æ¥­ç¨®"], current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®": ""})

    for _, row in df.iterrows():
        k, v = str(row["col0"]), str(row["col1"])
        if k in ["ä½æ‰€", "æ‰€åœ¨åœ°", "æœ¬ç¤¾æ‰€åœ¨åœ°"]:
            current["ä½æ‰€"] = clean_address(v)
        elif k in ["é›»è©±", "é›»è©±ç•ªå·", "TEL", "Tel", "tel"]:
            current["é›»è©±ç•ªå·"] = v
        elif k in ["æ¥­ç¨®", "äº‹æ¥­å†…å®¹", "ç”£æ¥­åˆ†é¡", "è£½é€ æ¥­ç¨®"]:
            current["æ¥­ç¨®"] = extract_industry(v)
        elif k and not v:
            if current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = k
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# 3) æ—¥æœ¬å€‰åº«å”ä¼šï¼ˆ4åˆ—ï¼‰
def extract_warehouse_association(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.fillna("")
    if df.shape[1] < 2:
        return pd.DataFrame(columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])
    while df.shape[1] < 4:
        df[f"__pad{df.shape[1]}"] = ""
    df = df.iloc[:, :4]
    df.columns = ["c0", "c1", "c2", "c3"]

    tel_re = re.compile(r"(?:TEL|Tel|tel)\s*([0-9ï¼-ï¼™\-ãƒ¼ï¼\s]+)")
    out, current = [], {"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()}

    def flush():
        if current["ä¼æ¥­å"]:
            out.append([current["ä¼æ¥­å"], "ãƒ»".join(current["æ¥­ç¨®_set"]), current["ä½æ‰€"], current["é›»è©±ç•ªå·"]])
        current.update({"ä¼æ¥­å": "", "ä½æ‰€": "", "é›»è©±ç•ªå·": "", "æ¥­ç¨®_set": set()})

    for _, r in df.iterrows():
        if r["c0"]:
            if current["ä¼æ¥­å"] and r["c0"] != current["ä¼æ¥­å"]:
                flush()
            current["ä¼æ¥­å"] = r["c0"]
        if r["c1"]:
            current["ä½æ‰€"] = clean_address(r["c1"])
        if r["c2"]:
            m = tel_re.search(r["c2"])
            if m:
                current["é›»è©±ç•ªå·"] = m.group(1).strip()
        if r["c3"]:
            current["æ¥­ç¨®_set"].add(extract_industry(r["c3"]))
    if current["ä¼æ¥­å"]:
        flush()
    return pd.DataFrame(out, columns=["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"])

# ===============================
# æ¥­ç¨®ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼/ãƒã‚¤ãƒ©ã‚¤ãƒˆ
# ===============================
remove_exact = [
    "ã‚ªãƒ•ã‚£ã‚¹æ©Ÿå™¨ãƒ¬ãƒ³ã‚¿ãƒ«æ¥­", "è¶³å ´ãƒ¬ãƒ³ã‚¿ãƒ«ä¼šç¤¾", "é›»æ°—å·¥", "å»ƒæ£„ç‰©ãƒªã‚µã‚¤ã‚¯ãƒ«æ¥­",
    "ãƒ—ãƒ­ãƒ‘ãƒ³è²©å£²æ¥­è€…", "çœ‹æ¿å°‚é–€åº—", "çµ¦æ°´è¨­å‚™å·¥å ´", "è­¦å‚™æ¥­", "å»ºè¨­ä¼šç¤¾",
    "å·¥å‹™åº—", "å†™çœŸåº—", "äººææ´¾é£æ¥­", "æ•´å‚™åº—", "å€‰åº«", "è‚‰åº—", "ç±³è²©å£²åº—",
    "ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒãƒ¼ã‚±ãƒƒãƒˆ", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚µãƒ¼ãƒ“ã‚¹", "å»ºæåº—",
    "è‡ªå‹•è»Šæ•´å‚™å·¥å ´", "è‡ªå‹•è»Šè²©å£²åº—", "è»Šä½“æ•´å‚™åº—", "å”ä¼š/çµ„ç¹”", "å»ºè¨­è«‹è² æ¥­è€…", "é›»å™¨åº—", "å®¶é›»é‡è²©åº—",
    "å»ºç¯‰ä¼šç¤¾", "ãƒã‚¦ã‚¹ ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ¥­", "ç„¼è‚‰åº—", "å»ºç¯‰è¨­è¨ˆäº‹å‹™æ‰€", "å·¦å®˜",
    "ä½œæ¥­æœåº—", "ç©ºèª¿è¨­å‚™å·¥äº‹æ¥­è€…", "é‡‘å±ã‚¹ã‚¯ãƒ©ãƒƒãƒ—æ¥­è€…", "å®³ç£é§†é™¤ã‚µãƒ¼ãƒ“ã‚¹",
    "ãƒ¢ãƒ¼ã‚¿ãƒ¼ä¿®ç†åº—", "ã‚¢ãƒ¼ãƒã‚§ãƒªãƒ¼ã‚·ãƒ§ãƒƒãƒ—", "ã‚¢ã‚¹ãƒ™ã‚¹ãƒˆæ¤œæŸ»æ¥­", "äº‹å‹™ç”¨å“åº—",
    "æ¸¬é‡å£«", "é…ç®¡æ¥­è€…", "åŠ´åƒçµ„åˆ", "ã‚¬ã‚¹ä¼šç¤¾", "ã‚¬ã‚½ãƒªãƒ³ã‚¹ã‚¿ãƒ³ãƒ‰",
    "ã‚¬ãƒ©ã‚¹/ãƒŸãƒ©ãƒ¼åº—", "ãƒ¯ã‚¤ãƒŠãƒªãƒ¼", "å±‹æ ¹ãµãæ¥­è€…", "é«˜ç­‰å­¦æ ¡", "é‡‘ç‰©åº—",
    "å²è·¡", "å•†å·¥ä¼šè­°æ‰€", "æ¸…æƒæ¥­", "æ¸…æƒæ¥­è€…", "é…ç®¡å·¥", "ãŠæ‰‹é ƒ"
]
remove_partial = ["è²©å£²åº—", "è²©å£²æ¥­è€…"]

highlight_partial = [
    "é‹è¼¸", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ã‚¯ã‚¹ã‚µãƒ¼ãƒ“ã‚¹", "å€‰åº«", "è¼¸é€ã‚µãƒ¼ãƒ“ã‚¹",
    "é‹é€ä¼šç¤¾ä¼æ¥­ã®ã‚ªãƒ•ã‚£ã‚¹", "é‹é€ä¼šç¤¾"
]

# ===============================
# æ¥­ç¨®ãƒã‚¤ã‚ºé™¤å»ï¼ˆãƒ¬ãƒ“ãƒ¥ãƒ¼/è©•ä¾¡ãªã©ï¼‰
# ===============================
def clean_industry_noise(s: str) -> str:
    """
    æ¥­ç¨®ã‚«ãƒ©ãƒ ã«ç´›ã‚Œè¾¼ã‚€ãƒ¬ãƒ“ãƒ¥ãƒ¼ç³»ãƒã‚¤ã‚ºã‚’å‰Šé™¤ã€‚
    ï¼‹ æœ€å¾Œã«ã€ŒÂ·ã€ã€Œãƒ¬ãƒ“ãƒ¥-ãªã—ã€ã€Œç©ºç™½ã ã‘ã€ã¯å¿…ãšæ¶ˆã™ã€‚
    """
    if not s:
        return ""
    t = str(s)
    t = re.sub(r"\s+", " ", t).strip()

    t = re.sub(r"^\s*\d+(?:\.\d+)?\s*[\(ï¼ˆ]\s*\d+\s*[\)ï¼‰]\s*(?:ä»¶)?\s*[ãƒ»ï½¥]?\s*", "", t)

    def norm_token(x: str) -> str:
        return re.sub(r"\s+", "", x)

    noise_basic = {"ãƒ¬ãƒ“ãƒ¥ãƒ¼", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã—", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ç„¡ã—", "ã‚¯ãƒã‚³ãƒŸ", "å£ã‚³ãƒŸ"}
    noise_nashi = {"ãªã—"}

    if t.startswith("ãƒ¬ãƒ“ãƒ¥ãƒ¼"):
        parts = [p.strip() for p in re.split(r"[ãƒ»ï½¥]", t) if p.strip()]
        if not parts:
            return ""
        if all(norm_token(p) in noise_basic | noise_nashi for p in parts):
            return ""
        cleaned_parts = []
        for p in parts:
            pn = norm_token(p)
            if pn in noise_basic or pn in noise_nashi:
                continue
            cleaned_parts.append(p)
        t = "ãƒ»".join(cleaned_parts)
    else:
        t = re.sub(r"(?:^|[ãƒ»ï½¥])\s*(Google\s*ã®?\s*ã‚¯ãƒã‚³ãƒŸ|å£ã‚³ãƒŸ|ã‚¯ãƒã‚³ãƒŸ)\s*(?=[ãƒ»ï½¥]|$)", "", t)
        t = re.sub(r"[ãƒ»ï½¥]?\s*\d+\s*ä»¶ã®?(ãƒ¬ãƒ“ãƒ¥ãƒ¼|å£ã‚³ãƒŸ|ã‚¯ãƒã‚³ãƒŸ)\s*(?=[ãƒ»ï½¥]|$)", "", t)

    parts = [p.strip() for p in re.split(r"[ãƒ»ï½¥]", t) if p.strip()]
    t = "ãƒ»".join(parts) if parts else ""
    t = re.sub(r"[ãƒ»ï½¥]{2,}", "ãƒ»", t).strip(" ãƒ»ï½¥")

    if t:
        for trash in ["Â·", "ãƒ¬ãƒ“ãƒ¥-ãªã—"]:
            t = t.replace(trash, "")
        t = re.sub(r"\s+", " ", t).strip()

    return t if t else ""

# ===============================
# å…±é€šæ•´å½¢ï¼ˆé›»è©±ã¯è§¦ã‚‰ãªã„ï¼‰
# ===============================
def clean_dataframe_except_phone(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    for c in ["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€"]:
        df[c] = df[c].map(normalize_text)
    df["æ¥­ç¨®"] = df["æ¥­ç¨®"].map(clean_industry_noise)
    return df.fillna("")

# ===============================
# UI
# ===============================
st.markdown("### ğŸ›¡ï¸ ä½¿ç”¨ã™ã‚‹NGãƒªã‚¹ãƒˆã‚’é¸æŠ")
nglist_files = [f for f in os.listdir() if f.endswith(".xlsx") and "NGãƒªã‚¹ãƒˆ" in f]
nglist_options = ["ãªã—"] + [os.path.splitext(f)[0] for f in nglist_files]
selected_nglist = st.selectbox(
    "NGãƒªã‚¹ãƒˆ",
    nglist_options,
    index=0,
    help="åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹ã€NGãƒªã‚¹ãƒˆã€œ.xlsxã€ã‚’æ¤œå‡ºã—ã¾ã™ã€‚1åˆ—ç›®=ä¼æ¥­åã€2åˆ—ç›®=é›»è©±ç•ªå·ï¼ˆä»»æ„ï¼‰ã€‚"
)

st.markdown("### ğŸ§­ æŠ½å‡ºæ–¹æ³•ã‚’é¸æŠ")
profile = st.selectbox(
    "æŠ½å‡ºãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«",
    ["Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰", "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰", "æ—¥æœ¬å€‰åº«å”ä¼šãƒªã‚¹ãƒˆï¼ˆ4åˆ—å‹ï¼‰"]
)

st.markdown("### ğŸ­ æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªã‚’é¸æŠ")
industry_option = st.radio("ã©ã®æ¥­ç¨®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«è©²å½“ã—ã¾ã™ã‹ï¼Ÿ", ("è£½é€ æ¥­", "ç‰©æµæ¥­", "ãã®ä»–"))

st.markdown("### ğŸ§© ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å–å¾—æ–¹æ³•ï¼ˆOSäº’æ›å¼·åŒ–ï¼‰")
template_source = st.radio(
    "template.xlsx ã®å–å¾—å…ƒ",
    ("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã® template.xlsx ã‚’ä½¿ã†ï¼ˆå¾“æ¥ï¼‰", "ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†"),
    index=0
)
template_upload = None
if template_source == "ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†":
    template_upload = st.file_uploader("template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx"], key="template_up")

uploaded_files = st.file_uploader(
    "ğŸ“¤ æ•´å½¢å¯¾è±¡ã®Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰",
    type=["xlsx"],
    accept_multiple_files=True
)

# ===============================
# NGãƒªã‚¹ãƒˆèª­ã¿è¾¼ã¿
# ===============================
ng_names = []
ng_phones = set()
if uploaded_files and selected_nglist != "ãªã—":
    ng_path = f"{selected_nglist}.xlsx"
    if not os.path.exists(ng_path):
        st.error(f"âŒ é¸æŠã•ã‚ŒãŸNGãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼š{ng_path}")
        st.stop()
    ng_df = pd.read_excel(ng_path, engine="openpyxl").fillna("")
    if ng_df.shape[1] < 1:
        st.error("âŒ NGãƒªã‚¹ãƒˆã¯å°‘ãªãã¨ã‚‚1åˆ—ï¼ˆä¼æ¥­åï¼‰ãŒå¿…è¦ã§ã™ã€‚2åˆ—ç›®ã«é›»è©±ç•ªå·ãŒã‚ã‚Œã°ç…§åˆã«åˆ©ç”¨ã—ã¾ã™ã€‚")
        st.stop()
    ng_df["__ng_company_canon"] = ng_df.iloc[:, 0].map(canonical_company_name)
    if ng_df.shape[1] >= 2:
        ng_df["__ng_digits"] = ng_df.iloc[:, 1].astype(str).map(phone_digits_only)
    else:
        ng_df["__ng_digits"] = ""
    ng_names = [n for n in ng_df["__ng_company_canon"].tolist() if n]
    ng_phones = set([d for d in ng_df["__ng_digits"].tolist() if d])

# ===============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===============================
if uploaded_files:
    for file_index, uploaded_file in enumerate(uploaded_files):
        st.markdown("---")
        st.markdown(f"## ğŸ“ {uploaded_file.name}")

        filename_no_ext = os.path.splitext(uploaded_file.name)[0]
        xl = pd.ExcelFile(uploaded_file, engine="openpyxl")

        # --- æŠ½å‡º ---
        if "å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼" in xl.sheet_names:
            df_raw = pd.read_excel(
                xl,
                sheet_name="å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼",
                header=None,
                engine="openpyxl"
            ).fillna("")
            df = pd.DataFrame({
                "ä¼æ¥­å": df_raw.iloc[1:, 1].astype(str),
                "æ¥­ç¨®": df_raw.iloc[1:, 2].astype(str),
                "ä½æ‰€": df_raw.iloc[1:, 3].astype(str),
                "é›»è©±ç•ªå·": df_raw.iloc[1:, 4].astype(str),
            })
        else:
            if profile == "Googleæ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦èª­ã¿ãƒ»é›»è©±ä¸Šä¸‹å‹ï¼‰":
                df0 = pd.read_excel(uploaded_file, header=None, engine="openpyxl").fillna("")
                lines = df0.iloc[:, 0].tolist()
                df = extract_google_vertical(lines)
            elif profile == "ã‚·ã‚´ãƒˆã‚¢ãƒ«ãƒ¯æ¤œç´¢ãƒªã‚¹ãƒˆï¼ˆç¸¦ç©ã¿ï¼‰":
                df0 = pd.read_excel(xl, header=None, engine="openpyxl").fillna("")
                df = extract_shigoto_arua(df0)
            else:
                df0 = pd.read_excel(xl, header=None, engine="openpyxl").fillna("")
                df = extract_warehouse_association(df0)

        df = clean_dataframe_except_phone(df)

        df["__company_canon"] = df["ä¼æ¥­å"].map(canonical_company_name)
        df["__digits"] = df["é›»è©±ç•ªå·"].map(phone_digits_only)

        removed_by_industry = 0
        if industry_option == "è£½é€ æ¥­":
            before = len(df)
            all_ng_words = remove_exact + remove_partial
            if all_ng_words:
                pat = "|".join(map(re.escape, all_ng_words))
                df = df[~df["æ¥­ç¨®"].str.contains(pat, na=False)]
            removed_by_industry = before - len(df)
            st.warning(f"ğŸ­ è£½é€ æ¥­ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼š{removed_by_industry}ä»¶ã‚’é™¤å¤–ã—ã¾ã—ãŸ")

        removal_logs = []
        company_removed = 0
        phone_removed = 0
        dup_removed = 0

        if ng_names or ng_phones:
            before = len(df)
            hit_idx = []
            for idx, row in df.iterrows():
                c = row["__company_canon"]
                if not c:
                    continue
                if any((n in c or c in n) for n in ng_names):
                    removal_logs.append({
                        "reason": "ng-company",
                        "company": row["ä¼æ¥­å"],
                        "phone_raw": row["é›»è©±ç•ªå·"],
                        "match": c
                    })
                    hit_idx.append(idx)
            if hit_idx:
                df = df.drop(index=hit_idx)
            company_removed = before - len(df)

            before = len(df)
            mask = df["__digits"].isin(ng_phones)
            if mask.any():
                for idx, row in df[mask].iterrows():
                    removal_logs.append({
                        "reason": "ng-phone",
                        "company": row["ä¼æ¥­å"],
                        "phone_raw": row["é›»è©±ç•ªå·"],
                        "match": row["__digits"]
                    })
                df = df[~mask]
            phone_removed = before - len(df)

        before = len(df)
        dup_mask = df["__digits"].ne("").astype(bool) & df["__digits"].duplicated(keep="first")
        if dup_mask.any():
            for idx, row in df[dup_mask].iterrows():
                removal_logs.append({
                    "reason": "dup-phone",
                    "company": row["ä¼æ¥­å"],
                    "phone_raw": row["é›»è©±ç•ªå·"],
                    "match": row["__digits"]
                })
            df = df[~dup_mask]
        dup_removed = before - len(df)

        df = df[~((df["ä¼æ¥­å"] == "") & (df["æ¥­ç¨®"] == "") & (df["ä½æ‰€"] == "") & (df["é›»è©±ç•ªå·"] == ""))].reset_index(drop=True)

        st.success(f"âœ… æ•´å½¢å®Œäº†ï¼š{len(df)}ä»¶ã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        edited = st.data_editor(
            df[["ä¼æ¥­å", "æ¥­ç¨®", "ä½æ‰€", "é›»è©±ç•ªå·"]],
            use_container_width=True,
            num_rows="fixed",
            column_config={
                "ä¼æ¥­å": st.column_config.TextColumn(required=True),
                "æ¥­ç¨®": st.column_config.TextColumn(),
                "ä½æ‰€": st.column_config.TextColumn(),
                "é›»è©±ç•ªå·": st.column_config.TextColumn(
                    help="åŸæ–‡ã®é…åˆ—ã‚’ä¿æŒã€‚å¿…è¦ãªã‚‰ã“ã“ã§æ‰‹å‹•ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚ç·¨é›†å†…å®¹ã¯ãã®ã¾ã¾å‡ºåŠ›ã«åæ˜ ã•ã‚Œã¾ã™ã€‚"
                ),
            },
            key=f"editable_preview_{file_index}",
        )

        df_export = edited.copy()

        with st.expander(f"ğŸ“Š å®Ÿè¡Œã‚µãƒãƒªãƒ¼ï¼ˆè©³ç´°ï¼‰ - {uploaded_file.name}", expanded=False):
            st.markdown(
                f"- ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é™¤å¤–ï¼ˆè£½é€ æ¥­ éƒ¨åˆ†ä¸€è‡´ï¼‰: **{removed_by_industry}** ä»¶\n"
                f"- NGï¼ˆä¼æ¥­å éƒ¨åˆ†ä¸€è‡´ï¼‰å‰Šé™¤: **{company_removed}** ä»¶\n"
                f"- NGï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{phone_removed}** ä»¶\n"
                f"- é‡è¤‡ï¼ˆé›»è©± digitsä¸€è‡´ï¼‰å‰Šé™¤: **{dup_removed}** ä»¶\n"
            )
            if removal_logs:
                log_df = pd.DataFrame(removal_logs)
                st.dataframe(log_df.head(300), use_container_width=True)
                csv_bytes = log_df.to_csv(index=False).encode("utf-8-sig")
                st.download_button(
                    "ğŸ§¾ å‰Šé™¤ãƒ­ã‚°ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=csv_bytes,
                    file_name=f"removal_logs_{filename_no_ext}.csv",
                    mime="text/csv",
                    key=f"removal_log_btn_{file_index}",
                )

        # ===============================
        # template.xlsx ã¸æ›¸ãè¾¼ã¿
        # ===============================
        wb = None
        if template_upload is not None:
            try:
                buf = io.BytesIO(template_upload.read())
                wb = load_workbook(buf)
            except Exception as e:
                st.error(f"âŒ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸ template.xlsx ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()
        else:
            app_dir = Path(__file__).resolve().parent
            template_path = app_dir / "template.xlsx"
            if not template_path.exists():
                st.error(
                    f"âŒ template.xlsx ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆæœŸå¾…ãƒ‘ã‚¹: {template_path}ï¼‰ã€‚"
                    "ã€ã“ã“ã§ template.xlsx ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ä½¿ã†ã€ã‚’é¸ã¶ã‹ã€"
                    "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚"
                )
                st.stop()
            try:
                wb = load_workbook(template_path)
            except Exception as e:
                st.error(f"âŒ template.xlsx ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                st.stop()

        if "å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼" not in wb.sheetnames:
            st.error("âŒ template.xlsx ã«ã€å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼ã€ã¨ã„ã†ã‚·ãƒ¼ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
            st.stop()

        sheet = wb["å…¥åŠ›ãƒã‚¹ã‚¿ãƒ¼"]

        for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row):
            for cell in row[1:5]:
                cell.value = None
                cell.fill = PatternFill(fill_type=None)

        red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

        def is_logi(val: str) -> bool:
            v = (val or "").strip()
            return any(word in v for word in highlight_partial)

        for idx_row, row in df_export.iterrows():
            r = idx_row + 2
            sheet.cell(row=r, column=2, value=row["ä¼æ¥­å"])
            sheet.cell(row=r, column=3, value=row["æ¥­ç¨®"])
            sheet.cell(row=r, column=4, value=row["ä½æ‰€"])
            sheet.cell(row=r, column=5, value=row["é›»è©±ç•ªå·"])
            if industry_option == "ç‰©æµæ¥­" and is_logi(row["æ¥­ç¨®"]):
                sheet.cell(row=r, column=3).fill = red_fill

        output = io.BytesIO()
        wb.save(output)
        output.seek(0)
        st.download_button(
            label=f"ğŸ“¥ æ•´å½¢æ¸ˆã¿ãƒªã‚¹ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ{filename_no_ext} / template.xlsx åæ˜ ï¼‰",
            data=output,
            file_name=f"{filename_no_ext}ãƒªã‚¹ãƒˆ.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            key=f"download_btn_{file_index}",
        )

else:
    st.info("Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚NGãƒªã‚¹ãƒˆxlsxã¯åŒãƒ•ã‚©ãƒ«ãƒ€ã«ç½®ãã‹ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆç›´ä¸‹ã«é…ç½®ã—ã¦ãã ã•ã„ã€‚")
