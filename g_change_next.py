import streamlit as st
import pandas as pd
import re
import io
import os
import unicodedata
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# =========================
# „Éö„Éº„Ç∏Ë®≠ÂÆöÔºè„Çπ„Çø„Ç§„É´
# =========================
st.set_page_config(page_title="G-Change Next", layout="wide")
st.markdown("""
    <style>
    h1 { color: #800000; }
    </style>
""", unsafe_allow_html=True)
st.title("üöó G-Change NextÔΩú‰ºÅÊ•≠ÊÉÖÂ†±Êï¥ÂΩ¢ÔºÜNGÈô§Â§ñ„ÉÑ„Éº„É´ÔºàVer5.1 ÂéüÊñáÈõªË©±‚ÄúÂÆåÂÖ®‰øùÊåÅ‚ÄùÔºèÂ∏ÇÂ§ñÂ±ÄÁï™„É≠„Ç∏„ÉÉ„ÇØÂâäÈô§Ôºâ")

# =========================
# „É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£ÔºàÊ≠£Ë¶èÂåñÁ≥ªÔºâ
# =========================
def nfkc(s: str) -> str:
    return unicodedata.normalize("NFKC", s)

def normalize_text(x) -> str:
    """ÂÖ±ÈÄö„ÅÆËªΩÈáèÊ≠£Ë¶èÂåñÔºöNFKC„ÄÅÁ©∫ÁôΩ„ÉªÂêÑÁ®Æ„ÉÄ„ÉÉ„Ç∑„É•Áµ±‰∏Ä„ÄÅÂâçÂæåÁ©∫ÁôΩÈô§ÂéªÔºàÈõªË©±Áï™Âè∑„Å´„ÅØ‰Ωø„Çè„Å™„ÅÑÔºâ"""
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return ""
    s = str(x).replace("\u3000", " ").replace("\xa0", " ")
    s = re.sub(r'[‚àí‚Äì‚Äî‚Äï„Éº]', '-', s)
    s = nfkc(s).strip()
    return s

def hiragana_to_katakana(s: str) -> str:
    res = []
    for ch in s:
        code = ord(ch)
        if 0x3041 <= code <= 0x3096:
            res.append(chr(code + 0x60))
        else:
            res.append(ch)
    return "".join(res)

COMPANY_SUFFIXES = [
    "Ê†™Âºè‰ºöÁ§æ", "(Ê†™)", "ÔºàÊ†™Ôºâ", "ÊúâÈôê‰ºöÁ§æ", "(Êúâ)", "ÔºàÊúâÔºâ",
    "inc.", "inc", "co.,ltd.", "co.,ltd", "co.ltd.", "co.ltd", "ltd.", "ltd",
    "corp.", "corp", "co.", "co",
    "ÂêàÂêå‰ºöÁ§æ", "ÂêàÂêç‰ºöÁ§æ", "ÂêàË≥á‰ºöÁ§æ"
]

def canonical_company_name(name: str) -> str:
    s = normalize_text(name)
    s = hiragana_to_katakana(s)
    s = s.casefold()
    for suf in sorted(COMPANY_SUFFIXES, key=len, reverse=True):
        s = s.replace(suf.casefold(), "")
    s = re.sub(r"[\s\-‚Äì‚Äî‚Äï‚Äê„Éº„Éª/,.¬∑ÔΩ•\(\)ÔºàÔºâ\[\]{}„Äê„ÄëÔºÜ&Ôºã+_|]", "", s)
    return s

HYPHENS = "-‚Äí‚Äì‚Äî‚Äï‚àíÔºç„Éº‚ÄêÔπ£\u2011"
HYPHENS_CLASS = re.escape(HYPHENS)

def phone_digits_only(s: str) -> str:
    """ÂÜÖÈÉ®ÊØîËºÉÁî®ÔºöÊï∞Â≠ó„Å†„Åë„Å´„Åô„ÇãÔºàË°®Á§∫„ÅØÂéüÊñá‰øùÊåÅÔºâ"""
    return re.sub(r"\D", "", str(s or ""))

# ‰ΩèÊâÄ„ÅÆËªΩÊï¥ÂΩ¢ÔºàÈõªË©±„Å´„ÅØ‰Ωø„Çè„Å™„ÅÑÔºâ
def clean_address(address: str) -> str:
    address = normalize_text(address)
    split_pattern = r"[¬∑ÔΩ•„Éª]"
    if re.search(split_pattern, address):
        return re.split(split_pattern, address)[-1].strip()
    return address

def extract_industry(line: str) -> str:
    parts = re.split(r"[¬∑„Éª]", normalize_text(line))
    return parts[-1].strip() if len(parts) > 1 else (normalize_text(line))

# =========================
# NG/Ê•≠Á®Æ„Éï„Ç£„É´„Çø„ÉºÔºàÁèæÁä∂Á∂≠ÊåÅÔºâ
# =========================
remove_exact = [
    "„Ç™„Éï„Ç£„ÇπÊ©üÂô®„É¨„É≥„Çø„É´Ê•≠", "Ë∂≥Â†¥„É¨„É≥„Çø„É´‰ºöÁ§æ", "ÈõªÊ∞óÂ∑•", "ÂªÉÊ£ÑÁâ©„É™„Çµ„Ç§„ÇØ„É´Ê•≠",
    "„Éó„É≠„Éë„É≥Ë≤©Â£≤Ê•≠ËÄÖ", "ÁúãÊùøÂ∞ÇÈñÄÂ∫ó", "Áµ¶Ê∞¥Ë®≠ÂÇôÂ∑•Â†¥", "Ë≠¶ÂÇôÊ•≠", "Âª∫Ë®≠‰ºöÁ§æ",
    "Â∑•ÂãôÂ∫ó", "ÂÜôÁúüÂ∫ó", "‰∫∫ÊùêÊ¥æÈÅ£Ê•≠", "Êï¥ÂÇôÂ∫ó", "ÂÄâÂ∫´", "ËÇâÂ∫ó", "Á±≥Ë≤©Â£≤Â∫ó",
    "„Çπ„Éº„Éë„Éº„Éû„Éº„Ç±„ÉÉ„Éà", "„É≠„Ç∏„Çπ„ÉÜ„Ç£„ÇØ„Çπ„Çµ„Éº„Éì„Çπ", "Âª∫ÊùêÂ∫ó",
    "Ëá™ÂãïËªäÊï¥ÂÇôÂ∑•Â†¥", "Ëá™ÂãïËªäË≤©Â£≤Â∫ó", "Ëªä‰ΩìÊï¥ÂÇôÂ∫ó", "Âçî‰ºö/ÁµÑÁπî", "Âª∫Ë®≠Ë´ãË≤†Ê•≠ËÄÖ", "ÈõªÂô®Â∫ó", "ÂÆ∂ÈõªÈáèË≤©Â∫ó", "Âª∫ÁØâ‰ºöÁ§æ", "„Éè„Ç¶„Çπ „ÇØ„É™„Éº„Éã„É≥„Ç∞Ê•≠", "ÁÑºËÇâÂ∫ó",
    "Âª∫ÁØâË®≠Ë®à‰∫ãÂãôÊâÄ","Â∑¶ÂÆò","‰ΩúÊ•≠ÊúçÂ∫ó","Á©∫Ë™øË®≠ÂÇôÂ∑•‰∫ãÊ•≠ËÄÖ","ÈáëÂ±û„Çπ„ÇØ„É©„ÉÉ„ÉóÊ•≠ËÄÖ","ÂÆ≥Áç£ÈßÜÈô§„Çµ„Éº„Éì„Çπ","„É¢„Éº„Çø„Éº‰øÆÁêÜÂ∫ó","„Ç¢„Éº„ÉÅ„Çß„É™„Éº„Ç∑„Éß„ÉÉ„Éó","„Ç¢„Çπ„Éô„Çπ„ÉàÊ§úÊüªÊ•≠","‰∫ãÂãôÁî®ÂìÅÂ∫ó",
    "Ê∏¨ÈáèÂ£´","ÈÖçÁÆ°Ê•≠ËÄÖ","Âä¥ÂÉçÁµÑÂêà","„Ç¨„Çπ‰ºöÁ§æ","„Ç¨„ÇΩ„É™„É≥„Çπ„Çø„É≥„Éâ","„Ç¨„É©„Çπ/„Éü„É©„ÉºÂ∫ó","„ÉØ„Ç§„Éä„É™„Éº","Â±ãÊ†π„Åµ„ÅçÊ•≠ËÄÖ","È´òÁ≠âÂ≠¶Ê†°","ÈáëÁâ©Â∫ó","Âè≤Ë∑°","ÂïÜÂ∑•‰ºöË≠∞ÊâÄ","Ê∏ÖÊéÉÊ•≠","Ê∏ÖÊéÉÊ•≠ËÄÖ","ÈÖçÁÆ°Â∑•"
]
remove_partial = ["Ë≤©Â£≤Â∫ó", "Ë≤©Â£≤Ê•≠ËÄÖ"]

highlight_partial = [
    "ÈÅãËº∏", "„É≠„Ç∏„Çπ„ÉÜ„Ç£„ÇØ„Çπ„Çµ„Éº„Éì„Çπ", "ÂÄâÂ∫´", "Ëº∏ÈÄÅ„Çµ„Éº„Éì„Çπ",
    "ÈÅãÈÄÅ‰ºöÁ§æ‰ºÅÊ•≠„ÅÆ„Ç™„Éï„Ç£„Çπ", "ÈÅãÈÄÅ‰ºöÁ§æ"
]

# =========================
# ÂÖ•ÂäõUIÔºàÂõ∫ÂÆö„Éó„É≠„Éï„Ç°„Ç§„É´Ôºâ
# =========================
nglist_files = [f for f in os.listdir() if f.endswith(".xlsx") and "NG„É™„Çπ„Éà" in f]
nglist_options = ["„Å™„Åó"] + [os.path.splitext(f)[0] for f in nglist_files]
selected_nglist = st.selectbox("üõ°Ô∏è ‰ΩøÁî®„Åô„ÇãNG„É™„Çπ„Éà„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ", nglist_options)

st.markdown("### üß≠ ÊäΩÂá∫ÊñπÊ≥ï„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
profile = st.selectbox(
    "ÊäΩÂá∫„Éó„É≠„Éï„Ç°„Ç§„É´",
    [
        "GoogleÊ§úÁ¥¢„É™„Çπ„ÉàÔºàÁ∏¶Ë™≠„Åø„ÉªÈõªË©±‰∏ä‰∏ãÂûãÔºâ",
        "„Ç∑„Ç¥„Éà„Ç¢„É´„ÉØÊ§úÁ¥¢„É™„Çπ„ÉàÔºàÁ∏¶Á©ç„Åø„É©„Éô„É´Ôºâ",
        "Êó•Êú¨ÂÄâÂ∫´Âçî‰ºö„É™„Çπ„ÉàÔºà4Âàó„ÉªË§áÊï∞Ë°å„Éñ„É≠„ÉÉ„ÇØÔºâ",
    ],
    index=0
)

st.markdown("### üè≠ Ê•≠Á®Æ„Ç´„ÉÜ„Ç¥„É™„ÇíÈÅ∏Êäû„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
industry_option = st.radio(
    "„Å©„ÅÆÊ•≠Á®Æ„Ç´„ÉÜ„Ç¥„É™„Éº„Å´Ë©≤ÂΩì„Åó„Åæ„Åô„ÅãÔºü",
    ("Ë£ΩÈÄ†Ê•≠", "Áâ©ÊµÅÊ•≠", "„Åù„ÅÆ‰ªñ")
)

uploaded_file = st.file_uploader("üì§ Êï¥ÂΩ¢ÂØæË±°„ÅÆExcel„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ", type=["xlsx"])

# =========================
# ÈõªË©±„ÅÆ‚ÄúÂéüÊñá‚ÄùÊäΩÂá∫ÔºàGoogleÁ∏¶ÂûãÁî®Ôºâ
# =========================
PHONE_TOKEN_RE = re.compile(rf"(\d{{2,4}}(?:[{HYPHENS_CLASS}\s]?\d{{2,4}}){{1,2}})")

def pick_phone_token_raw(line: str) -> str:
    s = str(line or "")
    m = PHONE_TOKEN_RE.search(s)
    return m.group(1).strip() if m else ""

# =========================
# ÊäΩÂá∫„É≠„Ç∏„ÉÉ„ÇØÔºà3ÊñπÂºèÔºâ‚ÄªÈõªË©±„ÅØÂéüÊñá‰øùÊåÅ
# =========================
# 1) GoogleÊ§úÁ¥¢„É™„Çπ„ÉàÔºö1ÂàóÁ∏¶„ÄÇÈõªË©±Ë°å„ÇíËª∏„Å´„ÄÅ‰∏ä3Ë°å„Çí ‰ºÅÊ•≠Âêç/Ê•≠Á®Æ/‰ΩèÊâÄ „Å®Âà§ÂÆö
def extract_google_vertical(lines):
    results = []
    rows = [str(l) for l in lines if str(l).strip() != ""]
    for i, line in enumerate(rows):
        ph_raw = pick_phone_token_raw(line)
        if ph_raw:
            phone = ph_raw  # ÂéüÊñá‰øùÊåÅ
            address = rows[i - 1] if i - 1 >= 0 else ""
            address = clean_address(address)
            industry = extract_industry(rows[i - 2]) if i - 2 >= 0 else ""
            company = rows[i - 3] if i - 3 >= 0 else ""
            results.append([company, industry, address, phone])
    return pd.DataFrame(results, columns=["‰ºÅÊ•≠Âêç", "Ê•≠Á®Æ", "‰ΩèÊâÄ", "ÈõªË©±Áï™Âè∑"])

# 2) „Ç∑„Ç¥„Éà„Ç¢„É´„ÉØÔºö2ÂàóÁ∏¶ÔºàÂ∑¶=„É©„Éô„É´/‰ºÅÊ•≠Âêç„ÄÅÂè≥=ÂÄ§Ôºâ
def extract_shigoto_arua(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.copy()
    if df.columns.size > 2:
        df = df.iloc[:, :2]
    df.columns = ["col0", "col1"]
    df["col0"] = df["col0"].map(lambda x: str(x) if pd.notnull(x) else "")
    df["col1"] = df["col1"].map(lambda x: str(x) if pd.notnull(x) else "")

    def norm_label(s: str) -> str:
        s = (s or "")
        s = re.sub(r"[Ôºö:]\s*$", "", s)
        return s

    label_to_field = {
        "‰ΩèÊâÄ": "‰ΩèÊâÄ",
        "ÊâÄÂú®Âú∞": "‰ΩèÊâÄ",
        "Êú¨Á§æÊâÄÂú®Âú∞": "‰ΩèÊâÄ",
        "ÈõªË©±": "ÈõªË©±Áï™Âè∑",
        "ÈõªË©±Áï™Âè∑": "ÈõªË©±Áï™Âè∑",
        "TEL": "ÈõªË©±Áï™Âè∑",
        "Tel": "ÈõªË©±Áï™Âè∑",
        "tel": "ÈõªË©±Áï™Âè∑",
        "Ê•≠Á®Æ": "Ê•≠Á®Æ",
        "‰∫ãÊ•≠ÂÜÖÂÆπ": "Ê•≠Á®Æ",
        "Áî£Ê•≠ÂàÜÈ°û": "Ê•≠Á®Æ",
        "Ë£ΩÈÄ†Ê•≠Á®Æ": "Ê•≠Á®Æ",
    }

    non_company_labels = set([
        "‰ΩèÊâÄ","ÊâÄÂú®Âú∞","Êú¨Á§æÊâÄÂú®Âú∞",
        "ÈõªË©±","ÈõªË©±Áï™Âè∑","TEL","Tel","tel",
        "FAX","Ôº¶Ôº°Ôº∏",
        "Ë≥áÊú¨Èáë","Ë≥áÊú¨ÈáëÔºàÂçÉÂÜÜÔºâ","Ë≥áÊú¨Èáë(ÂçÉÂÜÜ)",
        "ÂæìÊ•≠Âì°Êï∞","Ë®≠Á´ãÂπ¥Êúà",
        "Ê•≠Á®Æ","‰∫ãÊ•≠ÂÜÖÂÆπ","Áî£Ê•≠ÂàÜÈ°û","Ë£ΩÈÄ†Ê•≠Á®Æ"
    ])

    current = {"‰ºÅÊ•≠Âêç": "", "‰ΩèÊâÄ": "", "ÈõªË©±Áï™Âè∑": "", "Ê•≠Á®Æ": ""}
    out = []

    def flush_current():
        if current["‰ºÅÊ•≠Âêç"]:
            out.append([
                current["‰ºÅÊ•≠Âêç"],
                current["Ê•≠Á®Æ"],
                current["‰ΩèÊâÄ"],
                current["ÈõªË©±Áï™Âè∑"]  # ÂéüÊñá‰øùÊåÅ
            ])
        current["‰ºÅÊ•≠Âêç"] = ""
        current["‰ΩèÊâÄ"] = ""
        current["ÈõªË©±Áï™Âè∑"] = ""
        current["Ê•≠Á®Æ"] = ""

    for _, row in df.iterrows():
        left = norm_label(row["col0"])
        right = row["col1"]

        # ‰ºÅÊ•≠ÂêçÈñãÂßãÔºàÂè≥„ÅåÁ©∫„ÉªÂ∑¶„Åå„É©„Éô„É´Ë™û„Åß„Å™„ÅÑÔºâ
        if left and (right == "" or right is None) and left not in non_company_labels:
            if current["‰ºÅÊ•≠Âêç"]:
                flush_current()
            current["‰ºÅÊ•≠Âêç"] = left
            continue

        # „É©„Éô„É´Ë°åÔºàÂÄ§„ÅÇ„ÇäÔºâ
        if left in label_to_field and right:
            key = label_to_field[left]
            if key == "‰ΩèÊâÄ":
                current["‰ΩèÊâÄ"] = clean_address(right)
            elif key == "ÈõªË©±Áï™Âè∑":
                current["ÈõªË©±Áï™Âè∑"] = right  # ÂéüÊñá‰øùÊåÅ
            elif key == "Ê•≠Á®Æ":
                current["Ê•≠Á®Æ"] = extract_industry(right)
            continue

    if current["‰ºÅÊ•≠Âêç"]:
        flush_current()

    return pd.DataFrame(out, columns=["‰ºÅÊ•≠Âêç", "Ê•≠Á®Æ", "‰ΩèÊâÄ", "ÈõªË©±Áï™Âè∑"])

# 3) Êó•Êú¨ÂÄâÂ∫´Âçî‰ºöÔºö4Âàó√óË§áÊï∞Ë°å„Éñ„É≠„ÉÉ„ÇØ
def extract_warehouse_association(df_like: pd.DataFrame) -> pd.DataFrame:
    df = df_like.copy()
    if df.shape[1] < 2:
        return pd.DataFrame(columns=["‰ºÅÊ•≠Âêç","Ê•≠Á®Æ","‰ΩèÊâÄ","ÈõªË©±Áï™Âè∑"])

    while df.shape[1] < 4:
        df[f"__pad{df.shape[1]}"] = ""
    df = df.iloc[:, :4]
    df.columns = ["c0","c1","c2","c3"]
    for c in df.columns:
        df[c] = df[c].map(lambda x: str(x) if pd.notnull(x) else "")

    FACILITY_KEYWORDS = ["Âñ∂Ê•≠ÊâÄ","„Çª„É≥„Çø„Éº","ÊîØÂ∫ó","‰∫ãÊ•≠ÊâÄ","Âá∫ÂºµÊâÄ","ÂÄâÂ∫´","„Éá„Éù","Áâ©ÊµÅ„Çª„É≥„Çø„Éº","ÈÖçÈÄÅ„Çª„É≥„Çø„Éº"]
    LEGAL_KEYWORDS = ["Ê†™Âºè‰ºöÁ§æ","ÔºàÊ†™Ôºâ","(Ê†™)","ÊúâÈôê‰ºöÁ§æ","ÂêàÂêå‰ºöÁ§æ","ÂêàÂêç‰ºöÁ§æ","ÂêàË≥á‰ºöÁ§æ","Inc","INC","Co.,","CO.,","Ltd","LTD","Corp","CORP"]

    def looks_like_company(name: str) -> bool:
        if not name:
            return False
        if any(k in name for k in FACILITY_KEYWORDS):
            return False
        if any(k in name for k in LEGAL_KEYWORDS):
            return True
        return False

    out = []
    current = {"‰ºÅÊ•≠Âêç":"", "‰ΩèÊâÄ":"", "ÈõªË©±Áï™Âè∑":"", "Ê•≠Á®Æ_set":set()}

    def flush_current():
        if current["‰ºÅÊ•≠Âêç"]:
            industry = "„Éª".join([x for x in current["Ê•≠Á®Æ_set"] if x]) or ""
            out.append([
                current["‰ºÅÊ•≠Âêç"],
                industry,
                current["‰ΩèÊâÄ"],
                current["ÈõªË©±Áï™Âè∑"]  # ÂéüÊñá‰øùÊåÅ
            ])
        current["‰ºÅÊ•≠Âêç"] = ""
        current["‰ΩèÊâÄ"] = ""
        current["ÈõªË©±Áï™Âè∑"] = ""
        current["Ê•≠Á®Æ_set"] = set()

    tel_re = re.compile(r"(?:TEL|Tel|tel)\s*([0-9Ôºê-Ôºô\-ÔΩ∞„ÉºÔºç\s]+)")
    zip_re = re.compile(r"^„Äí\s*\d{3}-?\d{4}")

    for _, row in df.iterrows():
        c0, c1, c2, c3 = row["c0"], row["c1"], row["c2"], row["c3"]

        if c0 and looks_like_company(c0):
            if current["‰ºÅÊ•≠Âêç"] and c0 != current["‰ºÅÊ•≠Âêç"]:
                flush_current()
            current["‰ºÅÊ•≠Âêç"] = c0

        if c1:
            if zip_re.search(c1):
                if not current["‰ΩèÊâÄ"]:
                    current["‰ΩèÊâÄ"] = c1
                elif c1 not in current["‰ΩèÊâÄ"]:
                    current["‰ΩèÊâÄ"] = f"{current['‰ΩèÊâÄ']} {c1}".strip()
            else:
                if any(tok in c1 for tok in ["ÈÉΩ","ÈÅì","Â∫ú","Áúå","Â∏Ç","Âå∫","Áî∫","Êùë"]):
                    if current["‰ΩèÊâÄ"]:
                        if c1 not in current["‰ΩèÊâÄ"]:
                            current["‰ΩèÊâÄ"] = f"{current['‰ΩèÊâÄ']} {c1}".strip()
                    else:
                        current["‰ΩèÊâÄ"] = c1

        if c2:
            m = tel_re.search(c2)
            if m and not current["ÈõªË©±Áï™Âè∑"]:
                current["ÈõªË©±Áï™Âè∑"] = m.group(1).strip()  # ÂéüÊñá‰øùÊåÅ

        if c3:
            current["Ê•≠Á®Æ_set"].add(extract_industry(c3))

    if current["‰ºÅÊ•≠Âêç"]:
        flush_current()

    return pd.DataFrame(out, columns=["‰ºÅÊ•≠Âêç","Ê•≠Á®Æ","‰ΩèÊâÄ","ÈõªË©±Áï™Âè∑"])

# =========================
# ÂÖ±ÈÄö„É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£
# =========================
def clean_dataframe_except_phone(df: pd.DataFrame) -> pd.DataFrame:
    """‰ºÅÊ•≠Âêç„ÉªÊ•≠Á®Æ„Éª‰ΩèÊâÄ„ÅÆ„ÅøÊ≠£Ë¶èÂåñ„ÄÇÈõªË©±Áï™Âè∑„ÅØ‰∏ÄÂàáËß¶„Çâ„Å™„ÅÑ„ÄÇ"""
    df = df.copy()
    if "‰ºÅÊ•≠Âêç" in df.columns:
        df["‰ºÅÊ•≠Âêç"] = df["‰ºÅÊ•≠Âêç"].map(lambda x: normalize_text(x) if pd.notnull(x) else "")
    if "Ê•≠Á®Æ" in df.columns:
        df["Ê•≠Á®Æ"] = df["Ê•≠Á®Æ"].map(lambda x: normalize_text(x) if pd.notnull(x) else "")
    if "‰ΩèÊâÄ" in df.columns:
        df["‰ΩèÊâÄ"] = df["‰ΩèÊâÄ"].map(lambda x: clean_address(x) if pd.notnull(x) else "")
    # ÈõªË©±Áï™Âè∑„ÅØ‰øùÊåÅ
    return df.fillna("")

def remove_empty_rows(df):
    return df[~((df["‰ºÅÊ•≠Âêç"] == "") & (df["Ê•≠Á®Æ"] == "") & (df["‰ΩèÊâÄ"] == "") & (df["ÈõªË©±Áï™Âè∑"] == ""))]

# =========================
# „É°„Ç§„É≥Âá¶ÁêÜ
# =========================
if uploaded_file:
    filename_no_ext = os.path.splitext(uploaded_file.name)[0]
    xl = pd.ExcelFile(uploaded_file)

    # === ÂÖ•Âäõ„Éû„Çπ„Çø„ÉºÂÑ™ÂÖàÔºàÈõªË©±„ÅØÂéüÊñá‰øùÊåÅÔºâ===
    if "ÂÖ•Âäõ„Éû„Çπ„Çø„Éº" in xl.sheet_names:
        df_raw = pd.read_excel(xl, sheet_name="ÂÖ•Âäõ„Éû„Çπ„Çø„Éº", header=None).fillna("")
        result_df = pd.DataFrame({
            "‰ºÅÊ•≠Âêç": df_raw.iloc[:, 1].astype(str),
            "Ê•≠Á®Æ": df_raw.iloc[:, 2].astype(str),
            "‰ΩèÊâÄ": df_raw.iloc[:, 3].astype(str),
            "ÈõªË©±Áï™Âè∑": df_raw.iloc[:, 4].astype(str)  # ÂéüÊñá‰øùÊåÅ
        })
    else:
        # --- ÊäΩÂá∫ÔºàÂõ∫ÂÆö„Éó„É≠„Éï„Ç°„Ç§„É´Ôºâ ---
        if profile == "GoogleÊ§úÁ¥¢„É™„Çπ„ÉàÔºàÁ∏¶Ë™≠„Åø„ÉªÈõªË©±‰∏ä‰∏ãÂûãÔºâ":
            df = pd.read_excel(uploaded_file, header=None).fillna("")
            lines = df.iloc[:, 0].tolist()
            result_df = extract_google_vertical(lines)

        elif profile == "„Ç∑„Ç¥„Éà„Ç¢„É´„ÉØÊ§úÁ¥¢„É™„Çπ„ÉàÔºàÁ∏¶Á©ç„Åø„É©„Éô„É´Ôºâ":
            df0 = pd.read_excel(xl, sheet_name=xl.sheet_names[0], header=None).fillna("")
            result_df = extract_shigoto_arua(df0)

        else:  # Êó•Êú¨ÂÄâÂ∫´Âçî‰ºö
            df0 = pd.read_excel(xl, sheet_name=xl.sheet_names[0], header=None).fillna("")
            result_df = extract_warehouse_association(df0)

    # --- ÈùûÈõªË©±Âàó„ÅÆ„ÅøÊ≠£Ë¶èÂåñ ---
    result_df = clean_dataframe_except_phone(result_df)

    # --- ÊØîËºÉ„Ç≠„ÉºÔºà‰ºöÁ§æÂêçÊ≠£Ë¶èÂåñ„ÉªÈõªË©±digitsÔºâ ---
    result_df["__company_canon"] = result_df["‰ºÅÊ•≠Âêç"].map(canonical_company_name)
    result_df["__phone_digits"]  = result_df["ÈõªË©±Áï™Âè∑"].map(phone_digits_only)

    # --- Ê•≠Á®Æ„Éï„Ç£„É´„Çø„ÉºÔºàÁèæÁä∂Á∂≠ÊåÅÔºâ ---
    removed_by_industry = 0
    styled_df = None
    if industry_option == "Ë£ΩÈÄ†Ê•≠":
        before = len(result_df)
        result_df = result_df[~result_df["Ê•≠Á®Æ"].isin(remove_exact)]
        if remove_partial:
            pat = "|".join(map(re.escape, remove_partial))
            result_df = result_df[~result_df["Ê•≠Á®Æ"].str.contains(pat, na=False)]
        removed_by_industry = before - len(result_df)
        st.warning(f"üè≠ Ë£ΩÈÄ†Ê•≠„Éï„Ç£„É´„Çø„ÉºÈÅ©Áî®Ôºö{removed_by_industry}‰ª∂„ÇíÈô§Â§ñ„Åó„Åæ„Åó„Åü")

    elif industry_option == "Áâ©ÊµÅÊ•≠":
        def highlight_logistics(val):
            v = val or ""
            return "background-color: red" if any(word in v for word in highlight_partial) else ""
        styled_df = result_df.style.applymap(highlight_logistics, subset=["Ê•≠Á®Æ"])
        st.info("üöö Ê•≠Á®Æ„Åå‰∏ÄËá¥„Åó„Åü„Çª„É´„ÇíËµ§„Åè„Éè„Ç§„É©„Ç§„Éà„Åó„Å¶„ÅÑ„Åæ„ÅôÔºàÂá∫Âäõ„Å´„ÇÇÂèçÊò†Ôºâ")

    # --- NG„É™„Çπ„ÉàÔºèÈáçË§áÂâäÈô§ÔºàÈõªË©±„ÅØdigitsÁÖßÂêà„ÄÅË°®Á§∫„ÅØÂéüÊñá‰øùÊåÅÔºâ ---
    removal_logs = []
    company_removed = 0
    phone_removed = 0

    if selected_nglist != "„Å™„Åó":
        ng_path = f"{selected_nglist}.xlsx"
        if not os.path.exists(ng_path):
            st.error(f"‚ùå ÈÅ∏Êäû„Åï„Çå„ÅüNG„É™„Çπ„Éà„Éï„Ç°„Ç§„É´„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„ÇìÔºö{ng_path}")
            st.stop()
        ng_df = pd.read_excel(ng_path).fillna("")
        if ng_df.shape[1] < 2:
            st.error("‚ùå NG„É™„Çπ„Éà„ÅØ2Âàó‰ª•‰∏äÂøÖË¶Å„Åß„ÅôÔºà‰ºÅÊ•≠Âêç„ÄÅÈõªË©±Áï™Âè∑Ôºâ")
            st.stop()

        ng_df["__ng_company_canon"] = ng_df.iloc[:, 0].map(canonical_company_name)
        ng_df["__ng_phone_digits"]  = ng_df.iloc[:, 1].astype(str).map(phone_digits_only)

        ng_company_keys = ng_df["__ng_company_canon"].tolist()
        ng_phone_set    = set([p for p in ng_df["__ng_phone_digits"].tolist() if p])

        before = len(result_df)
        def hit_ng_company(canon_name: str):
            for ng in ng_company_keys:
                if ng and canon_name and (ng in canon_name or canon_name in ng):
                    return ng
            return None

        hit_indices = []
        for idx, row in result_df.iterrows():
            ng_key = hit_ng_company(row["__company_canon"])
            if ng_key:
                removal_logs.append({
                    "reason": "ng-company",
                    "source_company": row["‰ºÅÊ•≠Âêç"],
                    "source_phone": row["ÈõªË©±Áï™Âè∑"],  # ÂéüÊñá„Çí„É≠„Ç∞
                    "match_key": row["__company_canon"],
                    "ng_hit": ng_key
                })
                hit_indices.append(idx)
        if hit_indices:
            result_df = result_df.drop(index=hit_indices)
        company_removed = before - len(result_df)

        before = len(result_df)
        hits = result_df["__phone_digits"].isin(ng_phone_set)
        if hits.any():
            for idx, row in result_df[hits].iterrows():
                removal_logs.append({
                    "reason": "ng-phone",
                    "source_company": row["‰ºÅÊ•≠Âêç"],
                    "source_phone": row["ÈõªË©±Áï™Âè∑"],  # ÂéüÊñá„Çí„É≠„Ç∞
                    "match_key": row["__phone_digits"],
                    "ng_hit": row["__phone_digits"]
                })
            result_df = result_df[~hits]
        phone_removed = before - len(result_df)

    before = len(result_df)
    dup_mask = result_df["__phone_digits"].ne("").astype(bool) & result_df["__phone_digits"].duplicated(keep="first")
    if dup_mask.any():
        for idx, row in result_df[dup_mask].iterrows():
            removal_logs.append({
                "reason": "phone-duplicate",
                "source_company": row["‰ºÅÊ•≠Âêç"],
                "source_phone": row["ÈõªË©±Áï™Âè∑"],  # ÂéüÊñá„Çí„É≠„Ç∞
                "match_key": row["__phone_digits"],
                "ng_hit": ""
            })
        result_df = result_df[~dup_mask]
    removed_by_dedup = before - len(result_df)

    # --- Á©∫Ë°åÈô§Âéª„Éª‰∏¶„ÅπÊõø„ÅàÔºàÁ©∫ÈõªË©±„ÅØÊúÄÂæå„ÉªË°®Á§∫„ÅØÂéüÊñáÔºâ ---
    result_df = remove_empty_rows(result_df)
    result_df["_phdigits"] = result_df["__phone_digits"]
    result_df["_is_empty_phone"] = (result_df["_phdigits"] == "")
    result_df = result_df.sort_values(by=["_is_empty_phone", "_phdigits", "‰ºÅÊ•≠Âêç"]).drop(columns=["_phdigits","_is_empty_phone"])
    result_df = result_df.reset_index(drop=True)

    # === Á∑®ÈõÜÂèØËÉΩ„Éó„É¨„Éì„É•„ÉºÔºà‰ªªÊÑè„ÅßÊâãÂãï‰øÆÊ≠£ÂèØ„ÄÇÂéüÊñá„Çí„Åù„ÅÆ„Åæ„ÅæË¶ã„Åõ„ÇãÔºâ ===
    st.success(f"‚úÖ Êï¥ÂΩ¢ÂÆå‰∫ÜÔºö{len(result_df)}‰ª∂„ÅÆ‰ºÅÊ•≠„Éá„Éº„Çø„ÇíÂèñÂæó„Åó„Åæ„Åó„Åü„ÄÇ")
    display_df = result_df[["‰ºÅÊ•≠Âêç","Ê•≠Á®Æ","‰ΩèÊâÄ","ÈõªË©±Áï™Âè∑"]]

    st.caption("üîß Ë°®ÂÜÖ„ÅßÁõ¥Êé•Á∑®ÈõÜ„Åß„Åç„Åæ„Åô„ÄÇÁ∑®ÈõÜÂæå„ÅØ‰∏ã„ÅÆ„Äé„Åì„ÅÆÂÜÖÂÆπ„ÅßÁ¢∫ÂÆö„Äè„ÇíÊäº„Åô„Å®„ÄÅNGÁÖßÂêà„ÉªÈáçË§áË©ï‰æ°„Å®ExcelÂá∫Âäõ„Å´ÂèçÊò†„Åï„Çå„Åæ„Åô„ÄÇ")
    edited_df = st.data_editor(
        display_df,
        use_container_width=True,
        num_rows="fixed",
        column_config={
            "‰ºÅÊ•≠Âêç": st.column_config.TextColumn(required=True),
            "Ê•≠Á®Æ":   st.column_config.TextColumn(),
            "‰ΩèÊâÄ":   st.column_config.TextColumn(),
            "ÈõªË©±Áï™Âè∑": st.column_config.TextColumn(
                help="Ë°®Á§∫„ÉªÂá∫Âäõ„Å®„ÇÇ„Å´„Åì„ÅÆË°®Ë®ò„ÅÆ„Åæ„Åæ„ÄÇÂÜÖÈÉ®ÊØîËºÉ„ÅØdigits„ÅÆ„Åø„ÅßË°å„ÅÑ„Åæ„Åô„ÄÇ"
            ),
        },
        key="editable_preview",
    )

    if st.button("‚úÖ „Åì„ÅÆÂÜÖÂÆπ„ÅßÁ¢∫ÂÆöÔºàÂèçÊò†Ôºâ"):
        # ÂÄ§„ÇíÂèçÊò†
        result_df.loc[:, "‰ºÅÊ•≠Âêç"] = edited_df["‰ºÅÊ•≠Âêç"].values
        result_df.loc[:, "Ê•≠Á®Æ"] = edited_df["Ê•≠Á®Æ"].values
        result_df.loc[:, "‰ΩèÊâÄ"] = edited_df["‰ΩèÊâÄ"].values
        result_df.loc[:, "ÈõªË©±Áï™Âè∑"] = edited_df["ÈõªË©±Áï™Âè∑"].values
        # digits„ÇíÂÜçË®àÁÆóÔºàÂÜÖÈÉ®ÊØîËºÉÁî®Ôºâ
        result_df.loc[:, "__phone_digits"] = result_df["ÈõªË©±Áï™Âè∑"].map(phone_digits_only)
        st.success("Á∑®ÈõÜÂÜÖÂÆπ„ÇíÂèçÊò†„Åó„Åæ„Åó„Åü„ÄÇÂá∫Âäõ„ÅØ„Åì„ÅÆË°®Ë®ò„ÅÆ„Åæ„Åæ„Åß„Åô„ÄÇ")

    # --- „Çµ„Éû„É™„ÉºÔºàÂ∏ÇÂ§ñÂ±ÄÁï™Áõ£Êüª„ÅØÊí§ÂªÉÔºâ ---
    with st.expander("üìä ÂÆüË°å„Çµ„Éû„É™„ÉºÔºàË©≥Á¥∞Ôºâ"):
        st.markdown(f"""
- „Éï„Ç£„É´„Çø„ÉºÈô§Â§ñÔºàË£ΩÈÄ†Ê•≠ ÂÆåÂÖ®‰∏ÄËá¥Ôºã‰∏ÄÈÉ®ÈÉ®ÂàÜ‰∏ÄËá¥Ôºâ: **{removed_by_industry}** ‰ª∂  
- NGÔºà‰ºÅÊ•≠Âêç„ÉªÈÉ®ÂàÜ‰∏ÄËá¥ÔºâÂâäÈô§: **{company_removed}** ‰ª∂  
- NGÔºàÈõªË©±„ÉªÊï∞Â≠ó‰∏ÄËá¥ÔºâÂâäÈô§: **{phone_removed}** ‰ª∂  
- ÈáçË§áÔºàÈõªË©±„ÉªÊï∞Â≠ó‰∏ÄËá¥ÔºâÂâäÈô§: **{removed_by_dedup}** ‰ª∂  
""")
        if removal_logs:
            log_df = pd.DataFrame(removal_logs)
            st.dataframe(log_df.head(100), use_container_width=True)
            csv_bytes = log_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "üßæ ÂâäÈô§„É≠„Ç∞„ÇíCSV„Åß„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
                data=csv_bytes,
                file_name="removal_logs.csv",
                mime="text/csv"
            )

    # --- ExcelÂá∫ÂäõÔºàÈõªË©±„ÅØ‚ÄúÈõªË©±Áï™Âè∑‚ÄùÂàó„Åù„ÅÆ„Åæ„ÅæÔºâ ---
    template_file = "template.xlsx"
    if not os.path.exists(template_file):
        st.error("‚ùå template.xlsx „ÅåÂ≠òÂú®„Åó„Åæ„Åõ„Çì")
        st.stop()

    workbook = load_workbook(template_file)
    if "ÂÖ•Âäõ„Éû„Çπ„Çø„Éº" not in workbook.sheetnames:
        st.error("‚ùå template.xlsx „Å´„ÄéÂÖ•Âäõ„Éû„Çπ„Çø„Éº„Äè„Å®„ÅÑ„ÅÜ„Ç∑„Éº„Éà„ÅåÂ≠òÂú®„Åó„Åæ„Åõ„Çì„ÄÇ")
        st.stop()

    sheet = workbook["ÂÖ•Âäõ„Éû„Çπ„Çø„Éº"]
    for row in sheet.iter_rows(min_row=2, max_row=sheet.max_row):
        for cell in row[1:5]:
            cell.value = None
            cell.fill = PatternFill(fill_type=None)

    red_fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")

    def is_logi(val: str) -> bool:
        v = val or ""
        return any(word in v for word in highlight_partial)

    for idx, row in result_df.iterrows():
        r = idx + 2
        sheet.cell(row=r, column=2, value=row["‰ºÅÊ•≠Âêç"])
        sheet.cell(row=r, column=3, value=row["Ê•≠Á®Æ"])
        sheet.cell(row=r, column=4, value=row["‰ΩèÊâÄ"])
        sheet.cell(row=r, column=5, value=row["ÈõªË©±Áï™Âè∑"])  # ‚Üê ÂéüÊñá„ÅÆ„Åæ„ÅæÂá∫Âäõ
        if industry_option == "Áâ©ÊµÅÊ•≠" and is_logi(row["Ê•≠Á®Æ"]):
            sheet.cell(row=r, column=3).fill = red_fill

    output = io.BytesIO()
    workbook.save(output)
    output.seek(0)

    st.download_button(
        label="üì• Êï¥ÂΩ¢Ê∏à„Åø„É™„Çπ„Éà„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ",
        data=output,
        file_name=f"{filename_no_ext}„É™„Çπ„Éà.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )
else:
    st.info("template.xlsx „Å®ÔºàÂøÖË¶Å„Å™„ÇâÔºâNG„É™„Çπ„Éàxlsx„ÇíÂêå„Åò„Éï„Ç©„É´„ÉÄ„Å´ÁΩÆ„ÅÑ„Å¶„Åã„Çâ„ÄÅExcel„Éï„Ç°„Ç§„É´„Çí„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ")
